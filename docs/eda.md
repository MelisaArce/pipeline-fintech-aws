<div style="display: flex; justify-content: space-between; align-items: center; width: 100%;">
  
  <div style="flex: 1;">
    <h1>ğŸ§ª EDA del Dataset Berka</h1>
    <p>
      Este documento resume el AnÃ¡lisis Exploratorio de Datos (EDA) que realicÃ© sobre el Dataset Bancario Berka. Este anÃ¡lisis fue la base fundamental para todas las decisiones posteriores del proyecto ETL, el diseÃ±o de mi Data Lake House, la construcciÃ³n del modelo dimensional y los dashboards finales.
    </p>
  </div>

  <div style="flex-shrink: 0;">
    <img src="../img/logo-berka.png" alt="Logo Berka" width="150">
  </div>

</div>

---

# 1. ğŸ“Œ ConfiguraciÃ³n Inicial

## ğŸ“š LibrerÃ­as Utilizadas

Para explorar el dataset utilicÃ© las librerÃ­as estÃ¡ndar de anÃ¡lisis de datos en Python:

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```

* **pandas** â†’ para la exploraciÃ³n tabular
* **numpy** â†’ para operaciones numÃ©ricas
* **matplotlib / seaborn** â†’ para generar visualizaciones y distribuciones

## ğŸ“¦ Archivos Analizados

El dataset Berka estÃ¡ compuesto por mÃºltiples archivos separados, sin esquema y sin llaves relacionales explÃ­citas:

* `account.csv`
* `client.csv`
* `card.csv`
* `district.csv`
* `disp.csv`
* `loan.csv`
* `order.csv`
* `trans.csv`

Esto implicÃ³ un esfuerzo extra para reconstruir relaciones y estandarizar esquemas.

## ğŸ§ª Estrategia de Muestreo

Para optimizar tiempos y evitar cargas innecesarias â€”sobre todo en `trans.csv`, que es masivoâ€” tomÃ© una **muestra del 5%**:

```python
df_trans_sample = df_trans.sample(frac=0.05, random_state=42)
```

Gracias a esto pude analizar:

* volumen de transacciones
* montos atÃ­picos
* distribuciÃ³n temporal
* comportamiento por tipo de operaciÃ³n

Este muestreo fue clave para avanzar rÃ¡pido sin perder representatividad.

---

# 2. ğŸ” ExploraciÃ³n por Tabla

## ğŸŸ¦ 2.1. CLIENT

Variables relevantes:

* `client_id`
* `birth_number`
* `district_id`

### ğŸ”‘ Insight importante

DescubrÃ­ que `birth_number` codifica **fecha de nacimiento y gÃ©nero**.
A partir de eso generÃ©:

* `gender`
* `age`
* `age_segment`

Este hallazgo fue fundamental para el *Feature Engineering* y para los dashboards demogrÃ¡ficos.

---

## ğŸŸ§ 2.2. LOAN

Variables principales:

* `loan_id`, `account_id`, `amount`, `duration`, `payments`, `status`

### ğŸ” Insights

* Los montos estaban muy desbalanceados.
* Los status (`A, B, C, D`) no venÃ­an documentados, pero pude inferir que **C y D representan riesgo / default**.
* Este insight me llevÃ³ a crear la variable **`is_risky`** en la capa Curated.

---

## ğŸŸ© 2.3. DISTRICT

Incluye variables socioeconÃ³micas:

* salario promedio
* criminalidad
* desempleo
* poblaciÃ³n

### ğŸ” Insights

EncontrÃ© correlaciones entre:

* **menor salario promedio** â†’ mayores tasas de **default**
* ciertos distritos con patrones de riesgo mÃ¡s marcados

Esto justificÃ³ la creaciÃ³n de la dimensiÃ³n **`dim_district`**.

---

## ğŸŸª 2.4. TRANS (5% sample)

Variables clave:

* fecha
* monto
* tipo
* sÃ­mbolo bancario

### ğŸ” Insights

* EncontrÃ© outliers muy altos que requerÃ­an limpieza.
* Algunos `k_symbol` no tenÃ­an interpretaciÃ³n â†’ los clasifiquÃ© como `UNKNOWN`.
* DetectÃ© patrones Ãºtiles para crear features como:

  * `avg_trans_amount_3m`
  * `initial_balance`

Estos features enriquecieron el modelo dimensional.

---

# 3. ğŸ¯ Hallazgos que Guiaron Mi ETL

El EDA no fue un documento aislado: **fue el mapa** que definiÃ³ todas mis decisiones del pipeline.

## ğŸ”§ Limpieza (RAW â†’ PROCESSED)

ImplementÃ©:

* estandarizaciÃ³n `snake_case`
* conversiones de fecha
* imputaciones explÃ­citas
* cast de tipos correctos
* detecciÃ³n de outliers

## ğŸ§¬ Feature Engineering (PROCESSED â†’ CURATED)

A partir de lo que encontrÃ© en el EDA generÃ©:

* extracciÃ³n de gÃ©nero y edad
* segmentos demogrÃ¡ficos
* balances iniciales
* promedios mÃ³viles de transacciones
* flag de riesgo crediticio

## ğŸ›ï¸ Modelado Dimensional

Las tablas finales nacieron directamente del conocimiento exploratorio:

* `dim_client`
* `dim_loan`
* `dim_account`
* `dim_district`
* `fact_account_transactions`
* `fact_account_summary`

---

# 4. ğŸ“Š Conclusiones del EDA

### âœ”ï¸ El dataset tenÃ­a suficiente riqueza para construir un **modelo dimensional completo y realista**.

### âœ”ï¸ Fue necesario un fuerte proceso de limpieza por inconsistencias de origen.

### âœ”ï¸ El EDA definiÃ³ totalmente el camino del ETL:

* features demogrÃ¡ficos
* mÃ©tricas financieras
* clasificaciÃ³n de riesgo
* integraciÃ³n socioeconÃ³mica

### âœ”ï¸ TambiÃ©n definiÃ³ el enfoque de mis dashboards:

* riesgo por monto
* riesgo por edad
* riesgo por regiÃ³n

---
