{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e92e73",
   "metadata": {},
   "source": [
    "# üìä EDA Completo - Berka Dataset (Czech Banking Data)\n",
    "\n",
    "## üéØ Objetivo del An√°lisis\n",
    "\n",
    "Este notebook contiene el **An√°lisis Exploratorio de Datos (EDA) completo** sobre una muestra del 5% del Berka Dataset. Los objetivos son:\n",
    "\n",
    "1. **Identificar problemas de calidad de datos** (nulos, duplicados, inconsistencias)\n",
    "2. **Validar integridad estructural y relacional** (PKs, FKs, tipos de datos)\n",
    "3. **Descubrir patrones de negocio** (comportamiento transaccional, riesgo crediticio)\n",
    "4. **Definir el plan de transformaci√≥n ETL** para las capas Raw ‚Üí Processed ‚Üí Curated\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Tabla de Contenidos\n",
    "\n",
    "1. [Configuraci√≥n y Carga de Datos](#1-configuracion)\n",
    "2. [An√°lisis de Estructura y Esquema](#2-estructura)\n",
    "3. [An√°lisis de Calidad de Datos](#3-calidad)\n",
    "4. [An√°lisis de Integridad Relacional](#4-integridad)\n",
    "5. [An√°lisis Descriptivo por Tabla](#5-descriptivo)\n",
    "6. [An√°lisis de Negocio y Patrones](#6-negocio)\n",
    "7. [An√°lisis de Outliers y Anomal√≠as](#7-outliers)\n",
    "8. [Conclusiones y Plan ETL](#8-conclusiones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a108a6",
   "metadata": {},
   "source": [
    "<a id='1-configuracion'></a>\n",
    "## 1. ‚öôÔ∏è Configuraci√≥n y Carga de Datos\n",
    "\n",
    "### 1.1 Importaciones y Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f94f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n inicial completada\n",
      "üìÅ Directorio de entrada: ./data_original\n",
      "üìÅ Directorio de salida: ./data/raw/berka\n",
      "üìä Porcentaje de muestra: 5.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL PROYECTO ---\n",
    "INPUT_DIR = './data_original'\n",
    "OUTPUT_DIR = './data/raw/berka'\n",
    "SAMPLE_PERCENTAGE = 0.05  # Muestra del 5%\n",
    "RANDOM_SEED = 42\n",
    "SEPARATOR = ';'\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Archivos del dataset\n",
    "CSV_FILES = [\n",
    "    'account.csv', 'client.csv', 'disp.csv', 'loan.csv', \n",
    "    'order.csv', 'trans.csv', 'district.csv', 'card.csv'\n",
    "]\n",
    "\n",
    "# Diccionario para almacenar DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Definici√≥n de Claves Primarias\n",
    "PRIMARY_KEYS = {\n",
    "    'ACCOUNT': 'account_id',\n",
    "    'CLIENT': 'client_id',\n",
    "    'DISP': 'disp_id', \n",
    "    'LOAN': 'loan_id',\n",
    "    'ORDER': 'order_id',\n",
    "    'TRANS': 'trans_id',\n",
    "    'DEMOGRAPHIC': 'a1',  # district_id\n",
    "    'CARD': 'card_id'\n",
    "}\n",
    "\n",
    "# Definici√≥n de Claves For√°neas (Relaciones)\n",
    "FOREIGN_KEYS = {\n",
    "    ('DISP', 'account_id'): ('ACCOUNT', 'account_id'),\n",
    "    ('DISP', 'client_id'): ('CLIENT', 'client_id'),\n",
    "    ('LOAN', 'account_id'): ('ACCOUNT', 'account_id'),\n",
    "    ('ORDER', 'account_id'): ('ACCOUNT', 'account_id'),\n",
    "    ('TRANS', 'account_id'): ('ACCOUNT', 'account_id'),\n",
    "    ('CARD', 'disp_id'): ('DISP', 'disp_id'),\n",
    "    ('ACCOUNT', 'district_id'): ('DEMOGRAPHIC', 'a1')\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n inicial completada\")\n",
    "print(f\"üìÅ Directorio de entrada: {INPUT_DIR}\")\n",
    "print(f\"üìÅ Directorio de salida: {OUTPUT_DIR}\")\n",
    "print(f\"üìä Porcentaje de muestra: {SAMPLE_PERCENTAGE * 100}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ee3a6",
   "metadata": {},
   "source": [
    "### 1.2 Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594a79cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones auxiliares definidas\n"
     ]
    }
   ],
   "source": [
    "def limpiar_nombres_columnas(df):\n",
    "    \"\"\"\n",
    "    Limpia los nombres de las columnas:\n",
    "    - Elimina comillas y espacios\n",
    "    - Convierte a min√∫sculas\n",
    "    - Reemplaza espacios por guiones bajos\n",
    "    \"\"\"\n",
    "    df.columns = (df.columns\n",
    "                  .str.strip()\n",
    "                  .str.replace('\"', '', regex=False)\n",
    "                  .str.replace(\"'\", '', regex=False)\n",
    "                  .str.lower()\n",
    "                  .str.replace(' ', '_')\n",
    "                  .str.replace('-', '_'))\n",
    "    return df\n",
    "\n",
    "def detectar_separador(filepath, max_lines=5):\n",
    "    \"\"\"\n",
    "    Detecta autom√°ticamente el separador de un archivo CSV.\n",
    "    \"\"\"\n",
    "    separadores = [';', ',', '\\t', '|']\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        primeras_lineas = [f.readline() for _ in range(max_lines)]\n",
    "    \n",
    "    conteos = {sep: sum(linea.count(sep) for linea in primeras_lineas) \n",
    "               for sep in separadores}\n",
    "    \n",
    "    return max(conteos, key=conteos.get)\n",
    "\n",
    "def info_basica_tabla(df, nombre):\n",
    "    \"\"\"\n",
    "    Imprime informaci√≥n b√°sica de una tabla.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìã TABLA: {nombre}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\")\n",
    "    print(f\"   Memoria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"   Columnas: {', '.join(df.columns.tolist())}\")\n",
    "\n",
    "print(\"‚úÖ Funciones auxiliares definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080273c7",
   "metadata": {},
   "source": [
    "### 1.3 Muestreo y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39bb332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîÑ INICIANDO PROCESO DE MUESTREO Y CARGA\n",
      "======================================================================\n",
      "‚úÖ ACCOUNT      | Original:   4,500 | Muestra:    225 filas\n",
      "‚úÖ CLIENT       | Original:   5,369 | Muestra:    268 filas\n",
      "‚úÖ DISP         | Original:   5,369 | Muestra:    268 filas\n",
      "‚úÖ LOAN         | Original:     682 | Muestra:    682 filas\n",
      "‚úÖ ORDER        | Original:   6,471 | Muestra:    324 filas\n",
      "‚úÖ TRANS        | Original: 1,056,320 | Muestra: 52,816 filas\n",
      "‚úÖ DISTRICT     | Original:      77 | Muestra:     77 filas\n",
      "‚úÖ CARD         | Original:     892 | Muestra:    892 filas\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMEN DEL MUESTREO\n",
      "======================================================================\n",
      "   Tabla  Filas Originales  Filas Muestra  Columnas  % Muestreado\n",
      " ACCOUNT              4500            225         4          5.00\n",
      "  CLIENT              5369            268         3          4.99\n",
      "    DISP              5369            268         4          4.99\n",
      "    LOAN               682            682         7        100.00\n",
      "   ORDER              6471            324         6          5.01\n",
      "   TRANS           1056320          52816        10          5.00\n",
      "DISTRICT                77             77        16        100.00\n",
      "    CARD               892            892         4        100.00\n"
     ]
    }
   ],
   "source": [
    "def crear_muestras_y_cargar(input_dir, output_dir, sample_percentage, csv_files):\n",
    "    \"\"\"\n",
    "    Lee archivos originales, crea muestras y carga los DataFrames.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üîÑ INICIANDO PROCESO DE MUESTREO Y CARGA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"‚úÖ Directorio de salida creado: {output_dir}\")\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for filename in csv_files:\n",
    "        input_filepath = os.path.join(input_dir, filename)\n",
    "        output_filepath = os.path.join(output_dir, filename)\n",
    "        table_name = filename.replace('.csv', '').upper()\n",
    "        \n",
    "        if not os.path.exists(input_filepath):\n",
    "            print(f\"‚ö†Ô∏è  Archivo no encontrado: {filename}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Detectar separador\n",
    "            sep = detectar_separador(input_filepath)\n",
    "            \n",
    "            # Leer archivo original\n",
    "            df = pd.read_csv(input_filepath, sep=sep, low_memory=False)\n",
    "            df = limpiar_nombres_columnas(df)\n",
    "            \n",
    "            original_rows = len(df)\n",
    "            \n",
    "            # Aplicar muestreo\n",
    "            if original_rows > 1000:\n",
    "                sampled_df = df.sample(frac=sample_percentage, random_state=RANDOM_SEED)\n",
    "            else:\n",
    "                sampled_df = df.copy()\n",
    "            \n",
    "            sampled_rows = len(sampled_df)\n",
    "            \n",
    "            # Guardar muestra\n",
    "            sampled_df.to_csv(output_filepath, index=False, sep=';')\n",
    "            \n",
    "            # Almacenar en memoria\n",
    "            dataframes[table_name] = sampled_df\n",
    "            \n",
    "            # Registrar resultado\n",
    "            resultados.append({\n",
    "                'Tabla': table_name,\n",
    "                'Filas Originales': original_rows,\n",
    "                'Filas Muestra': sampled_rows,\n",
    "                'Columnas': len(sampled_df.columns),\n",
    "                '% Muestreado': (sampled_rows / original_rows * 100)\n",
    "            })\n",
    "            \n",
    "            print(f\"‚úÖ {table_name:12s} | Original: {original_rows:>7,} | Muestra: {sampled_rows:>6,} filas\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error procesando {filename}: {str(e)}\")\n",
    "    \n",
    "    # Resumen del muestreo\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä RESUMEN DEL MUESTREO\")\n",
    "    print(\"=\"*70)\n",
    "    df_resumen = pd.DataFrame(resultados)\n",
    "    print(df_resumen.to_string(index=False))\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Ejecutar muestreo y carga\n",
    "dataframes = crear_muestras_y_cargar(INPUT_DIR, OUTPUT_DIR, SAMPLE_PERCENTAGE, CSV_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2ddcd",
   "metadata": {},
   "source": [
    "<a id='2-estructura'></a>\n",
    "## 2. üìê An√°lisis de Estructura y Esquema\n",
    "\n",
    "### 2.1 Vista General del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d0a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üóÇÔ∏è  ESTRUCTURA GENERAL DEL DATASET BERKA\n",
      "======================================================================\n",
      "   Tabla  Filas  Columnas  Tama√±o (KB) Clave Primaria\n",
      "   TRANS  52816        10     12554.89       trans_id\n",
      "    CARD    892         4       118.20        card_id\n",
      "    LOAN    682         7        65.40        loan_id\n",
      "   ORDER    324         6        45.54       order_id\n",
      "  CLIENT    268         3         8.38      client_id\n",
      "    DISP    268         4        22.65        disp_id\n",
      " ACCOUNT    225         4        21.28     account_id\n",
      "DISTRICT     77        16        24.34            N/A\n",
      "\n",
      "üìä Total de tablas: 8\n",
      "üìä Total de filas (muestra): 55,552\n",
      "üìä Tama√±o total: 12860.68 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üóÇÔ∏è  ESTRUCTURA GENERAL DEL DATASET BERKA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "resumen_general = []\n",
    "\n",
    "for nombre, df in dataframes.items():\n",
    "    resumen_general.append({\n",
    "        'Tabla': nombre,\n",
    "        'Filas': len(df),\n",
    "        'Columnas': len(df.columns),\n",
    "        'Tama√±o (KB)': df.memory_usage(deep=True).sum() / 1024,\n",
    "        'Clave Primaria': PRIMARY_KEYS.get(nombre, 'N/A')\n",
    "    })\n",
    "\n",
    "df_resumen_general = pd.DataFrame(resumen_general)\n",
    "df_resumen_general = df_resumen_general.sort_values('Filas', ascending=False)\n",
    "print(df_resumen_general.to_string(index=False))\n",
    "\n",
    "print(f\"\\nüìä Total de tablas: {len(dataframes)}\")\n",
    "print(f\"üìä Total de filas (muestra): {df_resumen_general['Filas'].sum():,}\")\n",
    "print(f\"üìä Tama√±o total: {df_resumen_general['Tama√±o (KB)'].sum():.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a3673",
   "metadata": {},
   "source": [
    "### 2.2 Esquema Detallado por Tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41fe6e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: ACCOUNT\n",
      "======================================================================\n",
      "    Columna   Tipo  No Nulos  Nulos  % Nulos  √önicos          Ejemplo\n",
      " account_id  int64       225      0     0.00     225             2243\n",
      "district_id  int64       225      0     0.00      75               25\n",
      "  frequency object       225      0     0.00       3 POPLATEK MESICNE\n",
      "       date  int64       225      0     0.00     212           960124\n",
      "\n",
      "üîë Columnas ID encontradas: account_id, district_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: CLIENT\n",
      "======================================================================\n",
      "     Columna  Tipo  No Nulos  Nulos  % Nulos  √önicos  Ejemplo\n",
      "   client_id int64       268      0     0.00     268      431\n",
      "birth_number int64       268      0     0.00     267   276001\n",
      " district_id int64       268      0     0.00      75       24\n",
      "\n",
      "üîë Columnas ID encontradas: client_id, district_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: DISP\n",
      "======================================================================\n",
      "   Columna   Tipo  No Nulos  Nulos  % Nulos  √önicos Ejemplo\n",
      "   disp_id  int64       268      0     0.00     268     431\n",
      " client_id  int64       268      0     0.00     268     431\n",
      "account_id  int64       268      0     0.00     267     353\n",
      "      type object       268      0     0.00       2   OWNER\n",
      "\n",
      "üîë Columnas ID encontradas: disp_id, client_id, account_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: LOAN\n",
      "======================================================================\n",
      "   Columna    Tipo  No Nulos  Nulos  % Nulos  √önicos Ejemplo\n",
      "   loan_id   int64       682      0     0.00     682    5314\n",
      "account_id   int64       682      0     0.00     682    1787\n",
      "      date   int64       682      0     0.00     559  930705\n",
      "    amount   int64       682      0     0.00     645   96396\n",
      "  duration   int64       682      0     0.00       5      12\n",
      "  payments float64       682      0     0.00     577 8033.00\n",
      "    status  object       682      0     0.00       4       B\n",
      "\n",
      "üîë Columnas ID encontradas: loan_id, account_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: ORDER\n",
      "======================================================================\n",
      "   Columna    Tipo  No Nulos  Nulos  % Nulos  √önicos  Ejemplo\n",
      "  order_id   int64       324      0     0.00     324    31720\n",
      "account_id   int64       324      0     0.00     315     1573\n",
      "   bank_to  object       324      0     0.00      13       IJ\n",
      "account_to   int64       324      0     0.00     324 19240260\n",
      "    amount float64       324      0     0.00     313  3638.00\n",
      "  k_symbol  object       324      0     0.00       5     SIPO\n",
      "\n",
      "üîë Columnas ID encontradas: order_id, account_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: TRANS\n",
      "======================================================================\n",
      "   Columna    Tipo  No Nulos  Nulos  % Nulos  √önicos  Ejemplo\n",
      "  trans_id   int64     52816      0     0.00   52816   612452\n",
      "account_id   int64     52816      0     0.00    4459     2087\n",
      "      date   int64     52816      0     0.00    2077   980320\n",
      "      type  object     52816      0     0.00       3   PRIJEM\n",
      " operation  object     43542   9274    17.56       5    VKLAD\n",
      "    amount float64     52816      0     0.00   11957 10740.00\n",
      "   balance float64     52816      0     0.00   50423 79176.00\n",
      "  k_symbol  object     28774  24042    45.52       8      NaN\n",
      "      bank  object     13532  39284    74.38      13      NaN\n",
      "   account float64     14632  38184    72.30    5782      NaN\n",
      "\n",
      "‚ö†Ô∏è  Columnas con >50% nulos: bank, account\n",
      "\n",
      "üîë Columnas ID encontradas: trans_id, account_id\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: DISTRICT\n",
      "======================================================================\n",
      "Columna    Tipo  No Nulos  Nulos  % Nulos  √önicos     Ejemplo\n",
      "     a1   int64        77      0     0.00      77           1\n",
      "     a2  object        77      0     0.00      77 Hl.m. Praha\n",
      "     a3  object        77      0     0.00       8      Prague\n",
      "     a4   int64        77      0     0.00      77     1204953\n",
      "     a5   int64        77      0     0.00      53           0\n",
      "     a6   int64        77      0     0.00      36           0\n",
      "     a7   int64        77      0     0.00      17           0\n",
      "     a8   int64        77      0     0.00       6           1\n",
      "     a9   int64        77      0     0.00      11           1\n",
      "    a10 float64        77      0     0.00      70      100.00\n",
      "    a11   int64        77      0     0.00      76       12541\n",
      "    a12  object        77      0     0.00      71        0.29\n",
      "    a13 float64        77      0     0.00      73        0.43\n",
      "    a14   int64        77      0     0.00      44         167\n",
      "    a15  object        77      0     0.00      76       85677\n",
      "    a16   int64        77      0     0.00      76       99107\n",
      "\n",
      "======================================================================\n",
      "üìã ESQUEMA: CARD\n",
      "======================================================================\n",
      "Columna   Tipo  No Nulos  Nulos  % Nulos  √önicos         Ejemplo\n",
      "card_id  int64       892      0     0.00     892            1005\n",
      "disp_id  int64       892      0     0.00     892            9285\n",
      "   type object       892      0     0.00       3         classic\n",
      " issued object       892      0     0.00     607 931107 00:00:00\n",
      "\n",
      "üîë Columnas ID encontradas: card_id, disp_id\n"
     ]
    }
   ],
   "source": [
    "def analizar_esquema_tabla(df, nombre):\n",
    "    \"\"\"\n",
    "    Analiza el esquema de una tabla en detalle.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìã ESQUEMA: {nombre}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    esquema = pd.DataFrame({\n",
    "        'Columna': df.columns,\n",
    "        'Tipo': df.dtypes.values,\n",
    "        'No Nulos': df.count().values,\n",
    "        'Nulos': df.isnull().sum().values,\n",
    "        '% Nulos': (df.isnull().sum() / len(df) * 100).values,\n",
    "        '√önicos': [df[col].nunique() for col in df.columns],\n",
    "        'Ejemplo': [df[col].iloc[0] if len(df) > 0 else None for col in df.columns]\n",
    "    })\n",
    "    \n",
    "    print(esquema.to_string(index=False))\n",
    "    \n",
    "    # Identificar columnas problem√°ticas\n",
    "    cols_muchos_nulos = esquema[esquema['% Nulos'] > 50]['Columna'].tolist()\n",
    "    if cols_muchos_nulos:\n",
    "        print(f\"\\n‚ö†Ô∏è  Columnas con >50% nulos: {', '.join(cols_muchos_nulos)}\")\n",
    "    \n",
    "    # Identificar posibles IDs\n",
    "    cols_id = [col for col in df.columns if 'id' in col.lower()]\n",
    "    if cols_id:\n",
    "        print(f\"\\nüîë Columnas ID encontradas: {', '.join(cols_id)}\")\n",
    "\n",
    "# Analizar esquema de cada tabla\n",
    "for nombre, df in dataframes.items():\n",
    "    analizar_esquema_tabla(df, nombre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd2900",
   "metadata": {},
   "source": [
    "### 2.3 Detecci√≥n de Tipos de Datos Incorrectos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "620cda85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç DETECCI√ìN DE TIPOS DE DATOS INCORRECTOS\n",
      "======================================================================\n",
      "  Tabla      Columna Tipo Actual     Tipo Esperado  Ejemplo                               Acci√≥n\n",
      "ACCOUNT         date       int64          datetime   960124     Convertir de YYMMDD a YYYY-MM-DD\n",
      "   LOAN         date       int64          datetime   930705     Convertir de YYMMDD a YYYY-MM-DD\n",
      "  TRANS         date       int64          datetime   980320     Convertir de YYMMDD a YYYY-MM-DD\n",
      " CLIENT birth_number       int64 datetime + g√©nero   276001 Extraer fecha de nacimiento y g√©nero\n",
      "\n",
      "‚ùå Se encontraron 4 columnas con formato de fecha incorrecto\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç DETECCI√ìN DE TIPOS DE DATOS INCORRECTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Columnas que deber√≠an ser fechas (formato YYMMDD o YYYYMMDD)\n",
    "COLUMNAS_FECHA = {\n",
    "    'ACCOUNT': ['date'],\n",
    "    'LOAN': ['date'],\n",
    "    'TRANS': ['date'],\n",
    "    'CARD': ['issued']\n",
    "}\n",
    "\n",
    "# Columnas que contienen fechas en birth_number\n",
    "COLUMNAS_FECHA_ESPECIAL = {\n",
    "    'CLIENT': ['birth_number']  # YYMMDD con l√≥gica de g√©nero\n",
    "}\n",
    "\n",
    "def verificar_formato_fecha(df, col):\n",
    "    \"\"\"\n",
    "    Verifica si una columna tiene formato de fecha incorrecto (n√∫mero entero).\n",
    "    \"\"\"\n",
    "    if col in df.columns:\n",
    "        tipo_actual = df[col].dtype\n",
    "        ejemplo = df[col].iloc[0] if len(df) > 0 else None\n",
    "        \n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            return True, tipo_actual, ejemplo\n",
    "    \n",
    "    return False, None, None\n",
    "\n",
    "problemas_fecha = []\n",
    "\n",
    "for tabla, columnas in COLUMNAS_FECHA.items():\n",
    "    if tabla in dataframes:\n",
    "        df = dataframes[tabla]\n",
    "        for col in columnas:\n",
    "            es_problema, tipo, ejemplo = verificar_formato_fecha(df, col)\n",
    "            if es_problema:\n",
    "                problemas_fecha.append({\n",
    "                    'Tabla': tabla,\n",
    "                    'Columna': col,\n",
    "                    'Tipo Actual': tipo,\n",
    "                    'Tipo Esperado': 'datetime',\n",
    "                    'Ejemplo': ejemplo,\n",
    "                    'Acci√≥n': 'Convertir de YYMMDD a YYYY-MM-DD'\n",
    "                })\n",
    "\n",
    "for tabla, columnas in COLUMNAS_FECHA_ESPECIAL.items():\n",
    "    if tabla in dataframes:\n",
    "        df = dataframes[tabla]\n",
    "        for col in columnas:\n",
    "            es_problema, tipo, ejemplo = verificar_formato_fecha(df, col)\n",
    "            if es_problema:\n",
    "                problemas_fecha.append({\n",
    "                    'Tabla': tabla,\n",
    "                    'Columna': col,\n",
    "                    'Tipo Actual': tipo,\n",
    "                    'Tipo Esperado': 'datetime + g√©nero',\n",
    "                    'Ejemplo': ejemplo,\n",
    "                    'Acci√≥n': 'Extraer fecha de nacimiento y g√©nero'\n",
    "                })\n",
    "\n",
    "if problemas_fecha:\n",
    "    df_problemas = pd.DataFrame(problemas_fecha)\n",
    "    print(df_problemas.to_string(index=False))\n",
    "    print(f\"\\n‚ùå Se encontraron {len(problemas_fecha)} columnas con formato de fecha incorrecto\")\n",
    "else:\n",
    "    print(\"‚úÖ No se encontraron problemas con formatos de fecha\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fb496",
   "metadata": {},
   "source": [
    "<a id='3-calidad'></a>\n",
    "## 3. üîç An√°lisis de Calidad de Datos\n",
    "\n",
    "### 3.1 An√°lisis de Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a32915a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ùì AN√ÅLISIS DE VALORES NULOS Y VAC√çOS\n",
      "======================================================================\n",
      "\n",
      "### üìã ACCOUNT (225 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "### üìã CLIENT (268 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "### üìã DISP (268 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "### üìã LOAN (682 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "### üìã ORDER (324 filas)\n",
      " Columna  Nulos  % Nulos  No Nulos\n",
      "k_symbol     71    21.91       253\n",
      "\n",
      "### üìã TRANS (52,816 filas)\n",
      "  Columna  Nulos  % Nulos  No Nulos\n",
      "     bank  39284    74.38     13532\n",
      "  account  38184    72.30     14632\n",
      " k_symbol  26657    50.47     26159\n",
      "operation   9274    17.56     43542\n",
      "\n",
      "üí° Interpretaci√≥n: Los nulos en 'bank' y 'account' son ESPERADOS\n",
      "   ‚Üí Representan transacciones internas o en efectivo (VYBER, VKLAD)\n",
      "\n",
      "### üìã DISTRICT (77 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "### üìã CARD (892 filas)\n",
      "‚úÖ No se encontraron valores nulos\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMEN DE NULOS\n",
      "======================================================================\n",
      "   Tabla  Columnas con Nulos  Max % Nulos\n",
      " ACCOUNT                   0         0.00\n",
      "  CLIENT                   0         0.00\n",
      "    DISP                   0         0.00\n",
      "    LOAN                   0         0.00\n",
      "   ORDER                   1        21.91\n",
      "   TRANS                   4        74.38\n",
      "DISTRICT                   0         0.00\n",
      "    CARD                   0         0.00\n"
     ]
    }
   ],
   "source": [
    "def analizar_valores_nulos(df, nombre):\n",
    "    \"\"\"\n",
    "    Analiza valores nulos y vac√≠os en detalle.\n",
    "    \"\"\"\n",
    "    # Reemplazar valores vac√≠os por NaN\n",
    "    df_temp = df.replace({'': np.nan, ' ': np.nan, 'NULL': np.nan, 'null': np.nan})\n",
    "    \n",
    "    nulos = df_temp.isnull().sum()\n",
    "    total = len(df_temp)\n",
    "    porcentaje = (nulos / total * 100)\n",
    "    \n",
    "    info_nulos = pd.DataFrame({\n",
    "        'Columna': df_temp.columns,\n",
    "        'Nulos': nulos.values,\n",
    "        '% Nulos': porcentaje.values,\n",
    "        'No Nulos': (total - nulos).values\n",
    "    }).sort_values('% Nulos', ascending=False)\n",
    "    \n",
    "    # Filtrar solo columnas con nulos\n",
    "    info_nulos = info_nulos[info_nulos['Nulos'] > 0]\n",
    "    \n",
    "    return info_nulos\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ùì AN√ÅLISIS DE VALORES NULOS Y VAC√çOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "resumen_nulos = []\n",
    "\n",
    "for nombre, df in dataframes.items():\n",
    "    info_nulos = analizar_valores_nulos(df, nombre)\n",
    "    \n",
    "    print(f\"\\n### üìã {nombre} ({len(df):,} filas)\")\n",
    "    \n",
    "    if not info_nulos.empty:\n",
    "        print(info_nulos.to_string(index=False))\n",
    "        \n",
    "        # Interpretaci√≥n de negocio\n",
    "        if nombre == 'TRANS' and 'bank' in info_nulos['Columna'].values:\n",
    "            print(\"\\nüí° Interpretaci√≥n: Los nulos en 'bank' y 'account' son ESPERADOS\")\n",
    "            print(\"   ‚Üí Representan transacciones internas o en efectivo (VYBER, VKLAD)\")\n",
    "        \n",
    "        if nombre == 'ORDER' and 'bank_to' in info_nulos['Columna'].values:\n",
    "            print(\"\\nüí° Interpretaci√≥n: Los nulos en 'bank_to' y 'account_to' son ESPERADOS\")\n",
    "            print(\"   ‚Üí Representan √≥rdenes de pago internas\")\n",
    "        \n",
    "        resumen_nulos.append({\n",
    "            'Tabla': nombre,\n",
    "            'Columnas con Nulos': len(info_nulos),\n",
    "            'Max % Nulos': info_nulos['% Nulos'].max()\n",
    "        })\n",
    "    else:\n",
    "        print(\"‚úÖ No se encontraron valores nulos\")\n",
    "        resumen_nulos.append({\n",
    "            'Tabla': nombre,\n",
    "            'Columnas con Nulos': 0,\n",
    "            'Max % Nulos': 0\n",
    "        })\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESUMEN DE NULOS\")\n",
    "print(\"=\"*70)\n",
    "df_resumen_nulos = pd.DataFrame(resumen_nulos)\n",
    "print(df_resumen_nulos.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912dcb1",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 An√°lisis de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b24d37c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üëØ AN√ÅLISIS DE DUPLICADOS\n",
      "======================================================================\n",
      "\n",
      "### üîë ACCOUNT (PK: account_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (225 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë CLIENT (PK: client_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (268 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë DISP (PK: disp_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (268 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë LOAN (PK: loan_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (682 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë ORDER (PK: order_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (324 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë TRANS (PK: trans_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (52,816 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "### üîë CARD (PK: card_id)\n",
      "   ‚úÖ Clave Primaria √∫nica (892 valores √∫nicos)\n",
      "   ‚úÖ No hay filas completamente duplicadas\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMEN DE DUPLICADOS\n",
      "======================================================================\n",
      "  tabla         pk  total_filas  pk_duplicadas  filas_completas_duplicadas\n",
      "ACCOUNT account_id          225              0                           0\n",
      " CLIENT  client_id          268              0                           0\n",
      "   DISP    disp_id          268              0                           0\n",
      "   LOAN    loan_id          682              0                           0\n",
      "  ORDER   order_id          324              0                           0\n",
      "  TRANS   trans_id        52816              0                           0\n",
      "   CARD    card_id          892              0                           0\n"
     ]
    }
   ],
   "source": [
    "def analizar_duplicados(df, nombre, pk_col):\n",
    "    \"\"\"\n",
    "    Analiza duplicados en la clave primaria y filas completas.\n",
    "    \"\"\"\n",
    "    resultados = {\n",
    "        'tabla': nombre,\n",
    "        'pk': pk_col,\n",
    "        'total_filas': len(df),\n",
    "        'pk_duplicadas': 0,\n",
    "        'filas_completas_duplicadas': 0\n",
    "    }\n",
    "    \n",
    "    # Verificar que la PK existe\n",
    "    if pk_col not in df.columns:\n",
    "        print(f\"   ‚ùå ALERTA: Columna PK '{pk_col}' no encontrada\")\n",
    "        return resultados\n",
    "    \n",
    "    # 1. Duplicados en la Clave Primaria\n",
    "    pk_duplicates = df[df.duplicated(subset=[pk_col], keep=False)]\n",
    "    resultados['pk_duplicadas'] = len(pk_duplicates)\n",
    "    \n",
    "    # 2. Duplicados de filas completas\n",
    "    full_duplicates = df[df.duplicated(keep=False)]\n",
    "    resultados['filas_completas_duplicadas'] = len(full_duplicates)\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üëØ AN√ÅLISIS DE DUPLICADOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "resultados_duplicados = []\n",
    "\n",
    "for nombre, df in dataframes.items():\n",
    "    if nombre in PRIMARY_KEYS:\n",
    "        pk_col = PRIMARY_KEYS[nombre]\n",
    "        \n",
    "        print(f\"\\n### üîë {nombre} (PK: {pk_col})\")\n",
    "        \n",
    "        resultado = analizar_duplicados(df, nombre, pk_col)\n",
    "        resultados_duplicados.append(resultado)\n",
    "        \n",
    "        # Mostrar resultados\n",
    "        if resultado['pk_duplicadas'] > 0:\n",
    "            print(f\"   ‚ùå ERROR CR√çTICO: {resultado['pk_duplicadas']} filas con PK duplicada\")\n",
    "            print(f\"   ‚Üí La clave primaria DEBE ser √∫nica\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Clave Primaria √∫nica ({len(df):,} valores √∫nicos)\")\n",
    "        \n",
    "        if resultado['filas_completas_duplicadas'] > 0:\n",
    "            pct_dup = (resultado['filas_completas_duplicadas'] / len(df)) * 100\n",
    "            print(f\"   ‚ö†Ô∏è  {resultado['filas_completas_duplicadas']} filas completamente duplicadas ({pct_dup:.2f}%)\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ No hay filas completamente duplicadas\")\n",
    "\n",
    "# Resumen de duplicados\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESUMEN DE DUPLICADOS\")\n",
    "print(\"=\"*70)\n",
    "df_dup = pd.DataFrame(resultados_duplicados)\n",
    "print(df_dup[['tabla', 'pk', 'total_filas', 'pk_duplicadas', 'filas_completas_duplicadas']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7936e39",
   "metadata": {},
   "source": [
    "### 3.3 An√°lisis de Consistencia de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d66386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéØ AN√ÅLISIS DE CONSISTENCIA DE DATOS\n",
      "======================================================================\n",
      "\n",
      "### üìã ACCOUNT - Frecuencia de Estados de Cuenta\n",
      "frequency\n",
      "POPLATEK MESICNE      205\n",
      "POPLATEK TYDNE         18\n",
      "POPLATEK PO OBRATU      2\n",
      "Name: count, dtype: int64\n",
      "   ‚úÖ Todos los valores son v√°lidos\n",
      "\n",
      "### üìã TRANS - Tipos y Operaciones\n",
      "\n",
      "Tipos de transacci√≥n:\n",
      "type\n",
      "VYDAJ     31656\n",
      "PRIJEM    20340\n",
      "VYBER       820\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Operaciones:\n",
      "operation\n",
      "VYBER             21825\n",
      "PREVOD NA UCET    10255\n",
      "VKLAD              7789\n",
      "PREVOD Z UCTU      3277\n",
      "VYBER KARTOU        396\n",
      "Name: count, dtype: int64\n",
      "   ‚ö†Ô∏è  Tipos de transacci√≥n no v√°lidos: ['VYBER']\n",
      "\n",
      "### üìã LOAN - Estados de Pr√©stamos\n",
      "status\n",
      "C    403\n",
      "A    203\n",
      "D     45\n",
      "B     31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Interpretaci√≥n:\n",
      "   ‚Ä¢ A: Contrato terminado - Sin problemas\n",
      "   ‚Ä¢ B: Contrato activo - Sin problemas\n",
      "   ‚Ä¢ C: Contrato terminado - Pr√©stamo pagado correctamente\n",
      "   ‚Ä¢ D: Contrato activo - Cliente con deuda (RIESGO)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ AN√ÅLISIS DE CONSISTENCIA DE DATOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar consistency en columnas categ√≥ricas clave\n",
    "if 'ACCOUNT' in dataframes:\n",
    "    print(\"\\n### üìã ACCOUNT - Frecuencia de Estados de Cuenta\")\n",
    "    freq_counts = dataframes['ACCOUNT']['frequency'].value_counts()\n",
    "    print(freq_counts)\n",
    "    valores_esperados = ['POPLATEK MESICNE', 'POPLATEK TYDNE', 'POPLATEK PO OBRATU']\n",
    "    valores_invalidos = [v for v in freq_counts.index if v not in valores_esperados]\n",
    "    if valores_invalidos:\n",
    "        print(f\"   ‚ö†Ô∏è  Valores no esperados encontrados: {valores_invalidos}\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Todos los valores son v√°lidos\")\n",
    "\n",
    "if 'TRANS' in dataframes:\n",
    "    print(\"\\n### üìã TRANS - Tipos y Operaciones\")\n",
    "    print(\"\\nTipos de transacci√≥n:\")\n",
    "    print(dataframes['TRANS']['type'].value_counts())\n",
    "    print(\"\\nOperaciones:\")\n",
    "    print(dataframes['TRANS']['operation'].value_counts())\n",
    "    \n",
    "    # Verificar que type solo tenga 'PRIJEM' o 'VYDAJ'\n",
    "    tipos_validos = ['PRIJEM', 'VYDAJ', 'CREDIT', 'WITHDRAWAL']\n",
    "    tipos_encontrados = dataframes['TRANS']['type'].unique()\n",
    "    tipos_invalidos = [t for t in tipos_encontrados if t not in tipos_validos]\n",
    "    if tipos_invalidos:\n",
    "        print(f\"   ‚ö†Ô∏è  Tipos de transacci√≥n no v√°lidos: {tipos_invalidos}\")\n",
    "\n",
    "if 'LOAN' in dataframes:\n",
    "    print(\"\\n### üìã LOAN - Estados de Pr√©stamos\")\n",
    "    status_counts = dataframes['LOAN']['status'].value_counts()\n",
    "    print(status_counts)\n",
    "    print(\"\\n   Interpretaci√≥n:\")\n",
    "    print(\"   ‚Ä¢ A: Contrato terminado - Sin problemas\")\n",
    "    print(\"   ‚Ä¢ B: Contrato activo - Sin problemas\")\n",
    "    print(\"   ‚Ä¢ C: Contrato terminado - Pr√©stamo pagado correctamente\")\n",
    "    print(\"   ‚Ä¢ D: Contrato activo - Cliente con deuda (RIESGO)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b270c4",
   "metadata": {},
   "source": [
    "<a id='4-integridad'></a>\n",
    "## 4. üîó An√°lisis de Integridad Relacional\n",
    "\n",
    "### 4.1 Verificaci√≥n de Unicidad de Claves Primarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec107cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîë VERIFICACI√ìN DE UNICIDAD DE CLAVES PRIMARIAS\n",
      "======================================================================\n",
      "‚úÖ ACCOUNT      | PK 'account_id' es √öNICA (225 filas)\n",
      "‚úÖ CLIENT       | PK 'client_id' es √öNICA (268 filas)\n",
      "‚úÖ DISP         | PK 'disp_id' es √öNICA (268 filas)\n",
      "‚úÖ LOAN         | PK 'loan_id' es √öNICA (682 filas)\n",
      "‚úÖ ORDER        | PK 'order_id' es √öNICA (324 filas)\n",
      "‚úÖ TRANS        | PK 'trans_id' es √öNICA (52,816 filas)\n",
      "‚úÖ CARD         | PK 'card_id' es √öNICA (892 filas)\n",
      "\n",
      "  Tabla         PK  Total Filas  Valores √önicos  Duplicados Unicidad\n",
      "ACCOUNT account_id          225             225           0  ‚úÖ √önica\n",
      " CLIENT  client_id          268             268           0  ‚úÖ √önica\n",
      "   DISP    disp_id          268             268           0  ‚úÖ √önica\n",
      "   LOAN    loan_id          682             682           0  ‚úÖ √önica\n",
      "  ORDER   order_id          324             324           0  ‚úÖ √önica\n",
      "  TRANS   trans_id        52816           52816           0  ‚úÖ √önica\n",
      "   CARD    card_id          892             892           0  ‚úÖ √önica\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîë VERIFICACI√ìN DE UNICIDAD DE CLAVES PRIMARIAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "pk_results = []\n",
    "\n",
    "for nombre, pk_col in PRIMARY_KEYS.items():\n",
    "    if nombre in dataframes:\n",
    "        df = dataframes[nombre]\n",
    "        \n",
    "        if pk_col in df.columns:\n",
    "            total_rows = len(df)\n",
    "            unique_rows = df[pk_col].nunique()\n",
    "            duplicates = total_rows - unique_rows\n",
    "            \n",
    "            pk_results.append({\n",
    "                'Tabla': nombre,\n",
    "                'PK': pk_col,\n",
    "                'Total Filas': total_rows,\n",
    "                'Valores √önicos': unique_rows,\n",
    "                'Duplicados': duplicates,\n",
    "                'Unicidad': '‚úÖ √önica' if total_rows == unique_rows else '‚ùå Duplicada'\n",
    "            })\n",
    "            \n",
    "            if total_rows == unique_rows:\n",
    "                print(f\"‚úÖ {nombre:12s} | PK '{pk_col}' es √öNICA ({total_rows:,} filas)\")\n",
    "            else:\n",
    "                print(f\"‚ùå {nombre:12s} | PK '{pk_col}' tiene {duplicates:,} duplicados\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {nombre:12s} | PK '{pk_col}' NO ENCONTRADA\")\n",
    "\n",
    "df_pk_results = pd.DataFrame(pk_results)\n",
    "print(\"\\n\" + df_pk_results.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d1cf5",
   "metadata": {},
   "source": [
    "### 4.2 Verificaci√≥n de Integridad Referencial (Claves For√°neas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bab8ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîó VERIFICACI√ìN DE INTEGRIDAD REFERENCIAL (FK ‚Üí PK)\n",
      "======================================================================\n",
      "‚ùå DISP.account_id ‚Üí ACCOUNT.account_id | 253 valores sin referencia (94.8%)\n",
      "‚úÖ DISP.client_id ‚Üí CLIENT.client_id | Integridad OK\n",
      "‚ùå LOAN.account_id ‚Üí ACCOUNT.account_id | 648 valores sin referencia (95.0%)\n",
      "‚ùå ORDER.account_id ‚Üí ACCOUNT.account_id | 301 valores sin referencia (95.6%)\n",
      "‚ùå TRANS.account_id ‚Üí ACCOUNT.account_id | 4,239 valores sin referencia (95.1%)\n",
      "‚ùå CARD.disp_id ‚Üí DISP.disp_id | 844 valores sin referencia (94.6%)\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMEN DE INTEGRIDAD REFERENCIAL\n",
      "======================================================================\n",
      "FK Tabla FK Columna PK Tabla PK Columna  FK Valores  Sin Referencia  % Hu√©rfanos  Estado\n",
      "    DISP account_id  ACCOUNT account_id         267             253        94.76 ‚ùå ERROR\n",
      "    DISP  client_id   CLIENT  client_id         268               0         0.00    ‚úÖ OK\n",
      "    LOAN account_id  ACCOUNT account_id         682             648        95.01 ‚ùå ERROR\n",
      "   ORDER account_id  ACCOUNT account_id         315             301        95.56 ‚ùå ERROR\n",
      "   TRANS account_id  ACCOUNT account_id        4459            4239        95.07 ‚ùå ERROR\n",
      "    CARD    disp_id     DISP    disp_id         892             844        94.62 ‚ùå ERROR\n",
      "\n",
      "‚ö†Ô∏è  ALERTA CR√çTICA: Problemas de integridad debido al muestreo independiente\n",
      "   ‚Üí Causa: Muestreo del 5% por tabla rompe las relaciones FK-PK\n",
      "   ‚Üí Impacto: En producci√≥n (dataset completo), estos errores NO deber√≠an existir\n",
      "   ‚Üí Acci√≥n ETL: Validar integridad en datos completos, pero NO eliminar registros hu√©rfanos\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîó VERIFICACI√ìN DE INTEGRIDAD REFERENCIAL (FK ‚Üí PK)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fk_results = []\n",
    "\n",
    "for (fk_table, fk_col), (pk_table, pk_col) in FOREIGN_KEYS.items():\n",
    "    if fk_table in dataframes and pk_table in dataframes:\n",
    "        df_fk = dataframes[fk_table]\n",
    "        df_pk = dataframes[pk_table]\n",
    "        \n",
    "        # Ajustar nombre de columna si es necesario\n",
    "        pk_col_check = pk_col if pk_col in df_pk.columns else 'a1'\n",
    "        \n",
    "        if fk_col in df_fk.columns and pk_col_check in df_pk.columns:\n",
    "            # Valores de FK que NO existen en PK\n",
    "            fk_values = df_fk[fk_col].dropna().unique()\n",
    "            pk_values = df_pk[pk_col_check].dropna().unique()\n",
    "            \n",
    "            missing_refs = len([v for v in fk_values if v not in pk_values])\n",
    "            total_fk_values = len(fk_values)\n",
    "            missing_pct = (missing_refs / total_fk_values * 100) if total_fk_values > 0 else 0\n",
    "            \n",
    "            fk_results.append({\n",
    "                'FK Tabla': fk_table,\n",
    "                'FK Columna': fk_col,\n",
    "                'PK Tabla': pk_table,\n",
    "                'PK Columna': pk_col,\n",
    "                'FK Valores': total_fk_values,\n",
    "                'Sin Referencia': missing_refs,\n",
    "                '% Hu√©rfanos': missing_pct,\n",
    "                'Estado': '‚úÖ OK' if missing_refs == 0 else '‚ùå ERROR'\n",
    "            })\n",
    "            \n",
    "            if missing_refs == 0:\n",
    "                print(f\"‚úÖ {fk_table}.{fk_col} ‚Üí {pk_table}.{pk_col} | Integridad OK\")\n",
    "            else:\n",
    "                print(f\"‚ùå {fk_table}.{fk_col} ‚Üí {pk_table}.{pk_col} | {missing_refs:,} valores sin referencia ({missing_pct:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  {fk_table}.{fk_col} ‚Üí {pk_table}.{pk_col} | Columnas no encontradas\")\n",
    "\n",
    "if fk_results:\n",
    "    df_fk_results = pd.DataFrame(fk_results)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä RESUMEN DE INTEGRIDAD REFERENCIAL\")\n",
    "    print(\"=\"*70)\n",
    "    print(df_fk_results.to_string(index=False))\n",
    "    \n",
    "    # An√°lisis del problema de muestreo\n",
    "    errores_criticos = df_fk_results[df_fk_results['% Hu√©rfanos'] > 50]\n",
    "    if not errores_criticos.empty:\n",
    "        print(\"\\n‚ö†Ô∏è  ALERTA CR√çTICA: Problemas de integridad debido al muestreo independiente\")\n",
    "        print(\"   ‚Üí Causa: Muestreo del 5% por tabla rompe las relaciones FK-PK\")\n",
    "        print(\"   ‚Üí Impacto: En producci√≥n (dataset completo), estos errores NO deber√≠an existir\")\n",
    "        print(\"   ‚Üí Acci√≥n ETL: Validar integridad en datos completos, pero NO eliminar registros hu√©rfanos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9c4d1",
   "metadata": {},
   "source": [
    "<a id='5-descriptivo'></a>\n",
    "## 5. üìä An√°lisis Descriptivo por Tabla\n",
    "\n",
    "### 5.1 Estad√≠sticas Descriptivas de Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c32ac06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìà ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS\n",
      "======================================================================\n",
      "\n",
      "### üí∞ TRANS\n",
      "        amount   balance\n",
      "count 52816.00  52816.00\n",
      "mean   5972.97  38530.29\n",
      "std    9645.73  22059.96\n",
      "min       0.20 -27966.70\n",
      "1%       14.60   3449.76\n",
      "5%       14.60  13636.68\n",
      "10%      14.60  16289.50\n",
      "25%     131.80  22463.88\n",
      "50%    2066.00  33160.95\n",
      "75%    6860.50  49586.80\n",
      "90%   18641.50  68836.55\n",
      "95%   26300.00  82551.62\n",
      "99%   45701.30 108178.63\n",
      "max   87300.00 209637.00\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Rango: 0.20 a 87,300.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 6,728.70\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 161.49%\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Distribuci√≥n muy asim√©trica (skew: 2.59)\n",
      "\n",
      "   üìä balance:\n",
      "      ‚Ä¢ Rango: -27,966.70 a 209,637.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 27,122.93\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 57.25%\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Distribuci√≥n muy asim√©trica (skew: 1.23)\n",
      "\n",
      "### üí∞ LOAN\n",
      "         amount  payments  duration\n",
      "count    682.00    682.00    682.00\n",
      "mean  151410.18   4190.66     36.49\n",
      "std   113372.41   2215.83     17.08\n",
      "min     4980.00    304.00     12.00\n",
      "1%     12387.24    412.72     12.00\n",
      "5%     22972.20    963.90     12.00\n",
      "10%    34700.40   1451.80     12.00\n",
      "25%    66732.00   2477.00     24.00\n",
      "50%   116928.00   3934.00     36.00\n",
      "75%   210654.00   5813.50     48.00\n",
      "90%   317514.00   7370.00     60.00\n",
      "95%   388365.60   8048.20     60.00\n",
      "99%   477059.40   9301.44     60.00\n",
      "max   590820.00   9910.00     60.00\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Rango: 4,980.00 a 590,820.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 143,922.00\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 74.88%\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Distribuci√≥n muy asim√©trica (skew: 1.11)\n",
      "\n",
      "   üìä payments:\n",
      "      ‚Ä¢ Rango: 304.00 a 9,910.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 3,336.50\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 52.88%\n",
      "\n",
      "   üìä duration:\n",
      "      ‚Ä¢ Rango: 12.00 a 60.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 24.00\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 46.79%\n",
      "\n",
      "### üí∞ ORDER\n",
      "        amount\n",
      "count   324.00\n",
      "mean   2953.76\n",
      "std    2466.29\n",
      "min       4.00\n",
      "1%       20.99\n",
      "5%      158.05\n",
      "10%     404.50\n",
      "25%    1239.00\n",
      "50%    2273.00\n",
      "75%    3851.00\n",
      "90%    6600.64\n",
      "95%    8047.45\n",
      "99%   10557.50\n",
      "max   14584.00\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Rango: 4.00 a 14,584.00\n",
      "      ‚Ä¢ IQR (Q3-Q1): 2,612.00\n",
      "      ‚Ä¢ Coef. Variaci√≥n: 83.50%\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Distribuci√≥n muy asim√©trica (skew: 1.42)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà ESTAD√çSTICAS DESCRIPTIVAS - VARIABLES NUM√âRICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir columnas num√©ricas clave por tabla\n",
    "NUMERIC_COLS_KEY = {\n",
    "    'TRANS': ['amount', 'balance'],\n",
    "    'LOAN': ['amount', 'payments', 'duration'],\n",
    "    'ORDER': ['amount'],\n",
    "    'ACCOUNT': [],  # Solo tiene IDs y fechas\n",
    "    'CARD': [],\n",
    "    'DEMOGRAPHIC': ['a4', 'a11', 'a12', 'a13', 'a15', 'a16']  # Poblaci√≥n, salarios, desempleo, etc.\n",
    "}\n",
    "\n",
    "for tabla, columnas in NUMERIC_COLS_KEY.items():\n",
    "    if tabla in dataframes and columnas:\n",
    "        df = dataframes[tabla]\n",
    "        \n",
    "        # Filtrar columnas que realmente existen y son num√©ricas\n",
    "        cols_disponibles = [col for col in columnas \n",
    "                           if col in df.columns and pd.api.types.is_numeric_dtype(df[col])]\n",
    "        \n",
    "        if cols_disponibles:\n",
    "            print(f\"\\n### üí∞ {tabla}\")\n",
    "            \n",
    "            # Estad√≠sticas con percentiles clave\n",
    "            stats = df[cols_disponibles].describe(percentiles=[.01, .05, .10, .25, .50, .75, .90, .95, .99])\n",
    "            print(stats)\n",
    "            \n",
    "            # An√°lisis adicional\n",
    "            for col in cols_disponibles:\n",
    "                print(f\"\\n   üìä {col}:\")\n",
    "                print(f\"      ‚Ä¢ Rango: {df[col].min():,.2f} a {df[col].max():,.2f}\")\n",
    "                print(f\"      ‚Ä¢ IQR (Q3-Q1): {df[col].quantile(0.75) - df[col].quantile(0.25):,.2f}\")\n",
    "                print(f\"      ‚Ä¢ Coef. Variaci√≥n: {(df[col].std() / df[col].mean()):.2%}\")\n",
    "                \n",
    "                # Detectar asimetr√≠as\n",
    "                skew = df[col].skew()\n",
    "                if abs(skew) > 1:\n",
    "                    print(f\"      ‚Ä¢ ‚ö†Ô∏è  Distribuci√≥n muy asim√©trica (skew: {skew:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b40c14e",
   "metadata": {},
   "source": [
    "### 5.2 An√°lisis de Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1be004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä AN√ÅLISIS DE VARIABLES CATEG√ìRICAS\n",
      "======================================================================\n",
      "\n",
      "### üìã ACCOUNT\n",
      "\n",
      "   üîπ frequency:\n",
      "             Valor  Frecuencia  Porcentaje\n",
      "  POPLATEK MESICNE         205       91.11\n",
      "    POPLATEK TYDNE          18        8.00\n",
      "POPLATEK PO OBRATU           2        0.89\n",
      "\n",
      "### üìã TRANS\n",
      "\n",
      "   üîπ type:\n",
      " Valor  Frecuencia  Porcentaje\n",
      " VYDAJ       31656       59.94\n",
      "PRIJEM       20340       38.51\n",
      " VYBER         820        1.55\n",
      "\n",
      "   üîπ operation:\n",
      "         Valor  Frecuencia  Porcentaje\n",
      "         VYBER       21825       50.12\n",
      "PREVOD NA UCET       10255       23.55\n",
      "         VKLAD        7789       17.89\n",
      " PREVOD Z UCTU        3277        7.53\n",
      "  VYBER KARTOU         396        0.91\n",
      "\n",
      "   üîπ k_symbol:\n",
      "      Valor  Frecuencia  Porcentaje\n",
      "       UROK        9274       32.23\n",
      "     SLUZBY        7894       27.43\n",
      "       SIPO        5837       20.29\n",
      "                   2615        9.09\n",
      "     DUCHOD        1494        5.19\n",
      "   POJISTNE         915        3.18\n",
      "       UVER         657        2.28\n",
      "SANKC. UROK          88        0.31\n",
      "\n",
      "### üìã LOAN\n",
      "\n",
      "   üîπ status:\n",
      "Valor  Frecuencia  Porcentaje\n",
      "    C         403       59.09\n",
      "    A         203       29.77\n",
      "    D          45        6.60\n",
      "    B          31        4.55\n",
      "\n",
      "### üìã ORDER\n",
      "\n",
      "   üîπ k_symbol:\n",
      "   Valor  Frecuencia  Porcentaje\n",
      "    SIPO         176       54.32\n",
      "                  71       21.91\n",
      "POJISTNE          29        8.95\n",
      " LEASING          25        7.72\n",
      "    UVER          23        7.10\n",
      "\n",
      "### üìã CARD\n",
      "\n",
      "   üîπ type:\n",
      "  Valor  Frecuencia  Porcentaje\n",
      "classic         659       73.88\n",
      " junior         145       16.26\n",
      "   gold          88        9.87\n",
      "\n",
      "### üìã DISP\n",
      "\n",
      "   üîπ type:\n",
      "    Valor  Frecuencia  Porcentaje\n",
      "    OWNER         231       86.19\n",
      "DISPONENT          37       13.81\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä AN√ÅLISIS DE VARIABLES CATEG√ìRICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Definir columnas categ√≥ricas clave\n",
    "CATEGORICAL_COLS_KEY = {\n",
    "    'ACCOUNT': ['frequency'],\n",
    "    'TRANS': ['type', 'operation', 'k_symbol'],\n",
    "    'LOAN': ['status'],\n",
    "    'ORDER': ['k_symbol'],\n",
    "    'CARD': ['type'],\n",
    "    'DISP': ['type']\n",
    "}\n",
    "\n",
    "for tabla, columnas in CATEGORICAL_COLS_KEY.items():\n",
    "    if tabla in dataframes:\n",
    "        df = dataframes[tabla]\n",
    "        \n",
    "        print(f\"\\n### üìã {tabla}\")\n",
    "        \n",
    "        for col in columnas:\n",
    "            if col in df.columns:\n",
    "                print(f\"\\n   üîπ {col}:\")\n",
    "                value_counts = df[col].value_counts()\n",
    "                value_pcts = df[col].value_counts(normalize=True) * 100\n",
    "                \n",
    "                resultado = pd.DataFrame({\n",
    "                    'Valor': value_counts.index,\n",
    "                    'Frecuencia': value_counts.values,\n",
    "                    'Porcentaje': value_pcts.values\n",
    "                })\n",
    "                \n",
    "                print(resultado.to_string(index=False))\n",
    "                \n",
    "                # Alertas\n",
    "                if len(value_counts) == 1:\n",
    "                    print(\"      ‚ö†Ô∏è  Columna con un solo valor (considerar eliminar)\")\n",
    "                if len(value_counts) > 50:\n",
    "                    print(f\"      ‚ö†Ô∏è  Alta cardinalidad ({len(value_counts)} valores √∫nicos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ded5a0",
   "metadata": {},
   "source": [
    "### 5.3 An√°lisis de Distribuci√≥n Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "016651c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÖ AN√ÅLISIS TEMPORAL (Basado en columnas de fecha como enteros)\n",
      "======================================================================\n",
      "\n",
      "### üìÖ ACCOUNT - Distribuci√≥n por A√±o de Apertura\n",
      "year\n",
      "1993    52\n",
      "1994    26\n",
      "1995    30\n",
      "1996    63\n",
      "1997    54\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   üìä Rango: 1993 - 1997\n",
      "   üìä A√±o con m√°s aperturas: 1996 (63 cuentas)\n",
      "\n",
      "### üìÖ LOAN - Distribuci√≥n por A√±o de Pr√©stamo\n",
      "year\n",
      "1993     20\n",
      "1994    101\n",
      "1995     90\n",
      "1996    117\n",
      "1997    196\n",
      "1998    158\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   üìä Rango: 1993 - 1998\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÖ AN√ÅLISIS TEMPORAL (Basado en columnas de fecha como enteros)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Nota: Las fechas est√°n en formato YYMMDD como enteros\n",
    "# Ejemplo: 930101 = 1 de enero de 1993\n",
    "\n",
    "def parse_fecha_berka(fecha_int):\n",
    "    \"\"\"\n",
    "    Convierte fecha en formato YYMMDD (int) a a√±o.\n",
    "    Asume siglo 19 para a√±os >= 93.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fecha_str = str(int(fecha_int))\n",
    "        yy = int(fecha_str[:2])\n",
    "        year = 1900 + yy if yy >= 93 else 2000 + yy\n",
    "        return year\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Analizar distribuci√≥n de ACCOUNT por a√±o de apertura\n",
    "if 'ACCOUNT' in dataframes and 'date' in dataframes['ACCOUNT'].columns:\n",
    "    print(\"\\n### üìÖ ACCOUNT - Distribuci√≥n por A√±o de Apertura\")\n",
    "    df_account = dataframes['ACCOUNT'].copy()\n",
    "    df_account['year'] = df_account['date'].apply(parse_fecha_berka)\n",
    "    \n",
    "    year_dist = df_account['year'].value_counts().sort_index()\n",
    "    print(year_dist)\n",
    "    \n",
    "    print(f\"\\n   üìä Rango: {year_dist.index.min()} - {year_dist.index.max()}\")\n",
    "    print(f\"   üìä A√±o con m√°s aperturas: {year_dist.idxmax()} ({year_dist.max()} cuentas)\")\n",
    "\n",
    "# Analizar distribuci√≥n de LOAN por a√±o\n",
    "if 'LOAN' in dataframes and 'date' in dataframes['LOAN'].columns:\n",
    "    print(\"\\n### üìÖ LOAN - Distribuci√≥n por A√±o de Pr√©stamo\")\n",
    "    df_loan = dataframes['LOAN'].copy()\n",
    "    df_loan['year'] = df_loan['date'].apply(parse_fecha_berka)\n",
    "    \n",
    "    year_dist = df_loan['year'].value_counts().sort_index()\n",
    "    print(year_dist)\n",
    "    \n",
    "    print(f\"\\n   üìä Rango: {year_dist.index.min()} - {year_dist.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4b146",
   "metadata": {},
   "source": [
    "<a id='6-negocio'></a>\n",
    "## 6. üíº An√°lisis de Negocio y Patrones\n",
    "\n",
    "### 6.1 An√°lisis de Comportamiento Transaccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2df76c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üí≥ AN√ÅLISIS DE COMPORTAMIENTO TRANSACCIONAL\n",
      "======================================================================\n",
      "\n",
      "### üìä Distribuci√≥n de Transacciones por Tipo\n",
      "       trans_id   amount                      \n",
      "          count     mean   median          sum\n",
      "type                                          \n",
      "PRIJEM    20340  8012.10  1500.00 162966063.30\n",
      "VYBER       820 12565.39 12190.50  10303618.00\n",
      "VYDAJ     31656  4491.99  2024.00 142198566.00\n",
      "\n",
      "### üìä An√°lisis de Balance\n",
      "   ‚Ä¢ Balance promedio: 38,530.29\n",
      "   ‚Ä¢ Balance mediano: 33,160.95\n",
      "   ‚Ä¢ Balance m√≠nimo: -27,966.70\n",
      "   ‚Ä¢ Balance m√°ximo: 209,637.00\n",
      "\n",
      "   ‚ö†Ô∏è  Transacciones con balance negativo: 164 (0.31%)\n",
      "   ‚Ä¢ Balance negativo promedio: -3,523.18\n",
      "   ‚Üí Indica existencia de sobregiros o l√≠neas de cr√©dito\n",
      "\n",
      "### üìä Top 5 Operaciones M√°s Comunes\n",
      "operation\n",
      "VYBER             21825\n",
      "PREVOD NA UCET    10255\n",
      "VKLAD              7789\n",
      "PREVOD Z UCTU      3277\n",
      "VYBER KARTOU        396\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üí≥ AN√ÅLISIS DE COMPORTAMIENTO TRANSACCIONAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'TRANS' in dataframes:\n",
    "    df_trans = dataframes['TRANS']\n",
    "    \n",
    "    print(\"\\n### üìä Distribuci√≥n de Transacciones por Tipo\")\n",
    "    tipo_dist = df_trans.groupby('type').agg({\n",
    "        'trans_id': 'count',\n",
    "        'amount': ['mean', 'median', 'sum']\n",
    "    }).round(2)\n",
    "    print(tipo_dist)\n",
    "    \n",
    "    print(\"\\n### üìä An√°lisis de Balance\")\n",
    "    print(f\"   ‚Ä¢ Balance promedio: {df_trans['balance'].mean():,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Balance mediano: {df_trans['balance'].median():,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Balance m√≠nimo: {df_trans['balance'].min():,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Balance m√°ximo: {df_trans['balance'].max():,.2f}\")\n",
    "    \n",
    "    # Cuentas con balance negativo\n",
    "    balances_negativos = df_trans[df_trans['balance'] < 0]\n",
    "    if not balances_negativos.empty:\n",
    "        pct_neg = (len(balances_negativos) / len(df_trans)) * 100\n",
    "        print(f\"\\n   ‚ö†Ô∏è  Transacciones con balance negativo: {len(balances_negativos):,} ({pct_neg:.2f}%)\")\n",
    "        print(f\"   ‚Ä¢ Balance negativo promedio: {balances_negativos['balance'].mean():,.2f}\")\n",
    "        print(\"   ‚Üí Indica existencia de sobregiros o l√≠neas de cr√©dito\")\n",
    "    \n",
    "    print(\"\\n### üìä Top 5 Operaciones M√°s Comunes\")\n",
    "    top_operations = df_trans['operation'].value_counts().head(5)\n",
    "    print(top_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8beb9",
   "metadata": {},
   "source": [
    "### 6.2 An√°lisis de Riesgo Crediticio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eb15821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è  AN√ÅLISIS DE RIESGO CREDITICIO\n",
      "======================================================================\n",
      "\n",
      "### üìä Distribuci√≥n de Estados de Pr√©stamos\n",
      "Estado  Cantidad  Porcentaje\n",
      "     C       403       59.09\n",
      "     A       203       29.77\n",
      "     D        45        6.60\n",
      "     B        31        4.55\n",
      "\n",
      "   üìä Tasa de Pr√©stamos en Riesgo (B o D): 11.14%\n",
      "\n",
      "### üí∞ An√°lisis por Monto de Pr√©stamo y Estado\n",
      "        count      mean    median       sum\n",
      "status                                     \n",
      "A         203  91641.46  79632.00  18603216\n",
      "B          31 140720.90  96396.00   4362348\n",
      "C         403 171410.35 153504.00  69078372\n",
      "D          45 249284.53 260400.00  11217804\n",
      "\n",
      "### ‚è±Ô∏è  Duraci√≥n de Pr√©stamos por Estado\n",
      "        mean  median  min  max\n",
      "status                        \n",
      "A      22.23   24.00   12   60\n",
      "B      25.55   24.00   12   60\n",
      "C      43.44   48.00   12   60\n",
      "D      46.13   48.00   12   60\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ö†Ô∏è  AN√ÅLISIS DE RIESGO CREDITICIO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'LOAN' in dataframes:\n",
    "    df_loan = dataframes['LOAN']\n",
    "    \n",
    "    print(\"\\n### üìä Distribuci√≥n de Estados de Pr√©stamos\")\n",
    "    status_dist = df_loan['status'].value_counts()\n",
    "    status_pct = df_loan['status'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    status_summary = pd.DataFrame({\n",
    "        'Estado': status_dist.index,\n",
    "        'Cantidad': status_dist.values,\n",
    "        'Porcentaje': status_pct.values\n",
    "    })\n",
    "    print(status_summary.to_string(index=False))\n",
    "    \n",
    "    # Calcular tasa de riesgo\n",
    "    estados_riesgo = ['B', 'D']  # B = en curso sin problemas, D = en curso con deuda\n",
    "    prestamos_riesgo = df_loan[df_loan['status'].isin(estados_riesgo)]\n",
    "    tasa_riesgo = (len(prestamos_riesgo) / len(df_loan)) * 100\n",
    "    \n",
    "    print(f\"\\n   üìä Tasa de Pr√©stamos en Riesgo (B o D): {tasa_riesgo:.2f}%\")\n",
    "    \n",
    "    # An√°lisis por monto de pr√©stamo\n",
    "    print(\"\\n### üí∞ An√°lisis por Monto de Pr√©stamo y Estado\")\n",
    "    loan_by_status = df_loan.groupby('status')['amount'].agg(['count', 'mean', 'median', 'sum']).round(2)\n",
    "    print(loan_by_status)\n",
    "    \n",
    "    # Comparar duraci√≥n de pr√©stamos por estado\n",
    "    print(\"\\n### ‚è±Ô∏è  Duraci√≥n de Pr√©stamos por Estado\")\n",
    "    duration_by_status = df_loan.groupby('status')['duration'].agg(['mean', 'median', 'min', 'max']).round(2)\n",
    "    print(duration_by_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee32b88",
   "metadata": {},
   "source": [
    "### 6.3 An√°lisis Demogr√°fico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ba3d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üó∫Ô∏è  AN√ÅLISIS DEMOGR√ÅFICO POR REGI√ìN\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üó∫Ô∏è  AN√ÅLISIS DEMOGR√ÅFICO POR REGI√ìN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'DEMOGRAPHIC' in dataframes and 'ACCOUNT' in dataframes:\n",
    "    df_demo = dataframes['DEMOGRAPHIC']\n",
    "    df_account = dataframes['ACCOUNT']\n",
    "    \n",
    "    # Merge de cuentas con demograf√≠a\n",
    "    df_merged = pd.merge(\n",
    "        df_account,\n",
    "        df_demo,\n",
    "        left_on='district_id',\n",
    "        right_on='a1',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n### üìä Top 10 Regiones por N√∫mero de Cuentas\")\n",
    "    region_counts = df_merged['a3'].value_counts().head(10)\n",
    "    print(region_counts)\n",
    "    \n",
    "    print(\"\\n### üí∞ Salario Promedio por Frecuencia de Estado de Cuenta\")\n",
    "    if 'a11' in df_merged.columns and 'frequency' in df_merged.columns:\n",
    "        salary_by_freq = df_merged.groupby('frequency')['a11'].agg(['mean', 'median', 'count']).round(2)\n",
    "        print(salary_by_freq)\n",
    "    \n",
    "    print(\"\\n### üìä An√°lisis de Desempleo por Regi√≥n (Top 10)\")\n",
    "    if 'a13' in df_demo.columns and 'a3' in df_demo.columns:\n",
    "        unemployment = df_demo.nsmallest(10, 'a13')[['a3', 'a13']]\n",
    "        print(\"Regiones con MENOR desempleo:\")\n",
    "        print(unemployment.to_string(index=False))\n",
    "        \n",
    "        unemployment_high = df_demo.nlargest(10, 'a13')[['a3', 'a13']]\n",
    "        print(\"\\nRegiones con MAYOR desempleo:\")\n",
    "        print(unemployment_high.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ad76b",
   "metadata": {},
   "source": [
    "### 6.4 An√°lisis de Relaci√≥n Cliente-Cuenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97c06b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üë• AN√ÅLISIS DE RELACI√ìN CLIENTE-CUENTA\n",
      "======================================================================\n",
      "\n",
      "### üìä Distribuci√≥n de Tipos de Disposici√≥n\n",
      "     Tipo  Cantidad  Porcentaje\n",
      "    OWNER       231       86.19\n",
      "DISPONENT        37       13.81\n",
      "\n",
      "   üí° Interpretaci√≥n:\n",
      "   ‚Ä¢ OWNER: Cliente es el propietario principal de la cuenta\n",
      "   ‚Ä¢ DISPONENT: Cliente es un autorizado/usuario adicional\n",
      "\n",
      "### üìä N√∫mero de Disposiciones por Cliente\n",
      "   ‚Ä¢ Promedio de disposiciones por cliente: 1.00\n",
      "   ‚Ä¢ Mediana: 1\n",
      "   ‚Ä¢ M√°ximo: 1\n",
      "\n",
      "   üìä Clientes con m√∫ltiples cuentas: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üë• AN√ÅLISIS DE RELACI√ìN CLIENTE-CUENTA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'DISP' in dataframes:\n",
    "    df_disp = dataframes['DISP']\n",
    "    \n",
    "    print(\"\\n### üìä Distribuci√≥n de Tipos de Disposici√≥n\")\n",
    "    disp_type = df_disp['type'].value_counts()\n",
    "    disp_pct = df_disp['type'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    disp_summary = pd.DataFrame({\n",
    "        'Tipo': disp_type.index,\n",
    "        'Cantidad': disp_type.values,\n",
    "        'Porcentaje': disp_pct.values\n",
    "    })\n",
    "    print(disp_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n   üí° Interpretaci√≥n:\")\n",
    "    print(\"   ‚Ä¢ OWNER: Cliente es el propietario principal de la cuenta\")\n",
    "    print(\"   ‚Ä¢ DISPONENT: Cliente es un autorizado/usuario adicional\")\n",
    "    \n",
    "    # Cuentas por cliente\n",
    "    print(\"\\n### üìä N√∫mero de Disposiciones por Cliente\")\n",
    "    disp_per_client = df_disp.groupby('client_id').size()\n",
    "    print(f\"   ‚Ä¢ Promedio de disposiciones por cliente: {disp_per_client.mean():.2f}\")\n",
    "    print(f\"   ‚Ä¢ Mediana: {disp_per_client.median():.0f}\")\n",
    "    print(f\"   ‚Ä¢ M√°ximo: {disp_per_client.max():.0f}\")\n",
    "    \n",
    "    clientes_multiples_cuentas = disp_per_client[disp_per_client > 1]\n",
    "    pct_multiples = (len(clientes_multiples_cuentas) / len(disp_per_client)) * 100\n",
    "    print(f\"\\n   üìä Clientes con m√∫ltiples cuentas: {len(clientes_multiples_cuentas):,} ({pct_multiples:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a954cf85",
   "metadata": {},
   "source": [
    "<a id='7-outliers'></a>\n",
    "## 7. üìà An√°lisis de Outliers y Anomal√≠as\n",
    "\n",
    "### 7.1 Detecci√≥n de Outliers (M√©todo IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e82f096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìà DETECCI√ìN DE OUTLIERS Y ANOMAL√çAS\n",
      "======================================================================\n",
      "\n",
      "### üí∞ TRANS\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Q1: 131.80\n",
      "      ‚Ä¢ Q3: 6,860.50\n",
      "      ‚Ä¢ IQR: 6,728.70\n",
      "      ‚Ä¢ L√≠mite Inferior: -9,961.25\n",
      "      ‚Ä¢ L√≠mite Superior: 16,953.55\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Outliers encontrados: 6,036 (11.43%)\n",
      "      ‚Ä¢ Valor m√≠nimo outlier: 16,959.00\n",
      "      ‚Ä¢ Valor m√°ximo outlier: 87,300.00\n",
      "      ‚Üí Acci√≥n: Investigar transacciones/pr√©stamos grandes (fraude, VIP, errores)\n",
      "\n",
      "   üìä balance:\n",
      "      ‚Ä¢ Q1: 22,463.88\n",
      "      ‚Ä¢ Q3: 49,586.80\n",
      "      ‚Ä¢ IQR: 27,122.93\n",
      "      ‚Ä¢ L√≠mite Inferior: -18,220.51\n",
      "      ‚Ä¢ L√≠mite Superior: 90,271.19\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Outliers encontrados: 1,732 (3.28%)\n",
      "      ‚Ä¢ Valor m√≠nimo outlier: -27,966.70\n",
      "      ‚Ä¢ Valor m√°ximo outlier: 209,637.00\n",
      "      ‚Üí 3 cuentas con sobregiros severos\n",
      "\n",
      "### üí∞ LOAN\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Q1: 66,732.00\n",
      "      ‚Ä¢ Q3: 210,654.00\n",
      "      ‚Ä¢ IQR: 143,922.00\n",
      "      ‚Ä¢ L√≠mite Inferior: -149,151.00\n",
      "      ‚Ä¢ L√≠mite Superior: 426,537.00\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Outliers encontrados: 18 (2.64%)\n",
      "      ‚Ä¢ Valor m√≠nimo outlier: 428,784.00\n",
      "      ‚Ä¢ Valor m√°ximo outlier: 590,820.00\n",
      "      ‚Üí Acci√≥n: Investigar transacciones/pr√©stamos grandes (fraude, VIP, errores)\n",
      "\n",
      "   üìä payments:\n",
      "      ‚Ä¢ Q1: 2,477.00\n",
      "      ‚Ä¢ Q3: 5,813.50\n",
      "      ‚Ä¢ IQR: 3,336.50\n",
      "      ‚Ä¢ L√≠mite Inferior: -2,527.75\n",
      "      ‚Ä¢ L√≠mite Superior: 10,818.25\n",
      "      ‚Ä¢ ‚úÖ No se detectaron outliers significativos\n",
      "\n",
      "### üí∞ ORDER\n",
      "\n",
      "   üìä amount:\n",
      "      ‚Ä¢ Q1: 1,239.00\n",
      "      ‚Ä¢ Q3: 3,851.00\n",
      "      ‚Ä¢ IQR: 2,612.00\n",
      "      ‚Ä¢ L√≠mite Inferior: -2,679.00\n",
      "      ‚Ä¢ L√≠mite Superior: 7,769.00\n",
      "      ‚Ä¢ ‚ö†Ô∏è  Outliers encontrados: 19 (5.86%)\n",
      "      ‚Ä¢ Valor m√≠nimo outlier: 7,801.20\n",
      "      ‚Ä¢ Valor m√°ximo outlier: 14,584.00\n",
      "      ‚Üí Acci√≥n: Investigar transacciones/pr√©stamos grandes (fraude, VIP, errores)\n",
      "\n",
      "======================================================================\n",
      "üìä RESUMEN DE OUTLIERS\n",
      "======================================================================\n",
      "Tabla  Columna  Total Registros  Outliers  % Outliers  L√≠mite Superior  Max Valor\n",
      "TRANS   amount            52816      6036       11.43         16953.55   87300.00\n",
      "TRANS  balance            52816      1732        3.28         90271.19  209637.00\n",
      " LOAN   amount              682        18        2.64        426537.00  590820.00\n",
      " LOAN payments              682         0        0.00         10818.25    9910.00\n",
      "ORDER   amount              324        19        5.86          7769.00   14584.00\n"
     ]
    }
   ],
   "source": [
    "def detectar_outliers_iqr(df, col_name, threshold=1.5):\n",
    "    \"\"\"\n",
    "    Detecta outliers usando el m√©todo IQR (Rango Intercuart√≠lico).\n",
    "    threshold: Factor de IQR (1.5 = outliers moderados, 3.0 = outliers extremos)\n",
    "    \"\"\"\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    \n",
    "    outliers = df[(df[col_name] < lower_bound) | (df[col_name] > upper_bound)]\n",
    "    \n",
    "    return outliers, upper_bound, lower_bound, IQR\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà DETECCI√ìN DE OUTLIERS Y ANOMAL√çAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Columnas financieras para an√°lisis de outliers\n",
    "FINANCIAL_COLS_OUTLIERS = {\n",
    "    'TRANS': ['amount', 'balance'],\n",
    "    'LOAN': ['amount', 'payments'],\n",
    "    'ORDER': ['amount'],\n",
    "    'DEMOGRAPHIC': ['a11', 'a12', 'a13']  # Salarios y tasas\n",
    "}\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for tabla, columnas in FINANCIAL_COLS_OUTLIERS.items():\n",
    "    if tabla in dataframes:\n",
    "        df = dataframes[tabla]\n",
    "        \n",
    "        print(f\"\\n### üí∞ {tabla}\")\n",
    "        \n",
    "        for col in columnas:\n",
    "            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "                outliers, upper, lower, iqr = detectar_outliers_iqr(df, col)\n",
    "                \n",
    "                outlier_pct = (len(outliers) / len(df)) * 100\n",
    "                \n",
    "                print(f\"\\n   üìä {col}:\")\n",
    "                print(f\"      ‚Ä¢ Q1: {df[col].quantile(0.25):,.2f}\")\n",
    "                print(f\"      ‚Ä¢ Q3: {df[col].quantile(0.75):,.2f}\")\n",
    "                print(f\"      ‚Ä¢ IQR: {iqr:,.2f}\")\n",
    "                print(f\"      ‚Ä¢ L√≠mite Inferior: {lower:,.2f}\")\n",
    "                print(f\"      ‚Ä¢ L√≠mite Superior: {upper:,.2f}\")\n",
    "                \n",
    "                if not outliers.empty:\n",
    "                    print(f\"      ‚Ä¢ ‚ö†Ô∏è  Outliers encontrados: {len(outliers):,} ({outlier_pct:.2f}%)\")\n",
    "                    print(f\"      ‚Ä¢ Valor m√≠nimo outlier: {outliers[col].min():,.2f}\")\n",
    "                    print(f\"      ‚Ä¢ Valor m√°ximo outlier: {outliers[col].max():,.2f}\")\n",
    "                    \n",
    "                    # Interpretaci√≥n de negocio\n",
    "                    if col in ['amount', 'payments']:\n",
    "                        print(\"      ‚Üí Acci√≥n: Investigar transacciones/pr√©stamos grandes (fraude, VIP, errores)\")\n",
    "                    elif col == 'balance':\n",
    "                        balances_muy_negativos = outliers[outliers[col] < 0]\n",
    "                        if not balances_muy_negativos.empty:\n",
    "                            print(f\"      ‚Üí {len(balances_muy_negativos)} cuentas con sobregiros severos\")\n",
    "                else:\n",
    "                    print(\"      ‚Ä¢ ‚úÖ No se detectaron outliers significativos\")\n",
    "                \n",
    "                outlier_summary.append({\n",
    "                    'Tabla': tabla,\n",
    "                    'Columna': col,\n",
    "                    'Total Registros': len(df),\n",
    "                    'Outliers': len(outliers),\n",
    "                    '% Outliers': outlier_pct,\n",
    "                    'L√≠mite Superior': upper,\n",
    "                    'Max Valor': df[col].max()\n",
    "                })\n",
    "\n",
    "# Resumen de outliers\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESUMEN DE OUTLIERS\")\n",
    "print(\"=\"*70)\n",
    "df_outliers = pd.DataFrame(outlier_summary)\n",
    "print(df_outliers.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e95035",
   "metadata": {},
   "source": [
    "### 7.2 An√°lisis de Anomal√≠as Espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6876f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîç AN√ÅLISIS DE ANOMAL√çAS ESPEC√çFICAS\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  Cuentas sin transacciones en la muestra: 5\n",
      "   ‚Üí Nota: Esto puede ser debido al muestreo del 5%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîç AN√ÅLISIS DE ANOMAL√çAS ESPEC√çFICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Transacciones con montos = 0\n",
    "if 'TRANS' in dataframes:\n",
    "    df_trans = dataframes['TRANS']\n",
    "    trans_zero = df_trans[df_trans['amount'] == 0]\n",
    "    if not trans_zero.empty:\n",
    "        print(f\"\\n‚ö†Ô∏è  Transacciones con monto = 0: {len(trans_zero):,}\")\n",
    "        print(\"   ‚Üí Revisar: ¬øSon transacciones de ajuste o errores?\")\n",
    "\n",
    "# 2. Pr√©stamos con pagos inconsistentes\n",
    "if 'LOAN' in dataframes:\n",
    "    df_loan = dataframes['LOAN']\n",
    "    # Calcular pago mensual esperado\n",
    "    df_loan['expected_payment'] = df_loan['amount'] / df_loan['duration']\n",
    "    df_loan['payment_diff'] = abs(df_loan['payments'] - df_loan['expected_payment'])\n",
    "    df_loan['payment_diff_pct'] = (df_loan['payment_diff'] / df_loan['expected_payment']) * 100\n",
    "    \n",
    "    pagos_inconsistentes = df_loan[df_loan['payment_diff_pct'] > 10]  # >10% de diferencia\n",
    "    if not pagos_inconsistentes.empty:\n",
    "        print(f\"\\n‚ö†Ô∏è  Pr√©stamos con pagos inconsistentes: {len(pagos_inconsistentes):,}\")\n",
    "        print(f\"   ‚Üí Diferencia >10% entre pago mensual y pago esperado\")\n",
    "        print(f\"   ‚Üí Podr√≠a indicar cambios en t√©rminos o errores de c√°lculo\")\n",
    "\n",
    "# 3. Cuentas sin transacciones\n",
    "if 'ACCOUNT' in dataframes and 'TRANS' in dataframes:\n",
    "    accounts_with_trans = dataframes['TRANS']['account_id'].unique()\n",
    "    all_accounts = dataframes['ACCOUNT']['account_id'].unique()\n",
    "    accounts_no_trans = [acc for acc in all_accounts if acc not in accounts_with_trans]\n",
    "    \n",
    "    if accounts_no_trans:\n",
    "        print(f\"\\n‚ö†Ô∏è  Cuentas sin transacciones en la muestra: {len(accounts_no_trans)}\")\n",
    "        print(\"   ‚Üí Nota: Esto puede ser debido al muestreo del 5%\")\n",
    "\n",
    "# 4. Clientes sin cuentas (por problema de FK)\n",
    "if 'CLIENT' in dataframes and 'DISP' in dataframes:\n",
    "    clients_with_accounts = dataframes['DISP']['client_id'].unique()\n",
    "    all_clients = dataframes['CLIENT']['client_id'].unique()\n",
    "    clients_no_accounts = [cli for cli in all_clients if cli not in clients_with_accounts]\n",
    "    \n",
    "    if clients_no_accounts:\n",
    "        pct = (len(clients_no_accounts) / len(all_clients)) * 100\n",
    "        print(f\"\\n‚ö†Ô∏è  Clientes sin cuentas: {len(clients_no_accounts)} ({pct:.2f}%)\")\n",
    "        print(\"   ‚Üí Nota: Esto puede ser debido al muestreo del 5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82434f6",
   "metadata": {},
   "source": [
    "<a id='8-conclusiones'></a>\n",
    "## 8. üìã Conclusiones y Plan de Transformaci√≥n ETL\n",
    "\n",
    "### 8.1 Resumen Ejecutivo de Hallazgos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c6315",
   "metadata": {},
   "source": [
    "### üéØ HALLAZGOS CR√çTICOS\n",
    "\n",
    "#### 1. ‚ùå PROBLEMAS DE FORMATO Y ESTRUCTURA\n",
    "   - Fechas almacenadas como enteros (YYMMDD) en todas las tablas\n",
    "   - Cabeceras con comillas dobles y separador ';' en archivos originales\n",
    "   - Columna 'a1' en DEMOGRAPHIC deber√≠a llamarse 'district_id'\n",
    "   - Nombres de columnas inconsistentes (mezcla de c√≥digos y nombres)\n",
    "\n",
    "#### 2. ‚ö†Ô∏è  PROBLEMAS DE CALIDAD DE DATOS\n",
    "   - Valores nulos funcionales en TRANS.bank y ORDER.bank_to (representan transacciones internas)\n",
    "   - No se encontraron duplicados en claves primarias (‚úÖ)\n",
    "   - Balances negativos v√°lidos (indican sobregiros o l√≠neas de cr√©dito)\n",
    "   - Outliers significativos en TRANS.amount y LOAN.amount (requieren investigaci√≥n)\n",
    "\n",
    "#### 3. üîó PROBLEMAS DE INTEGRIDAD REFERENCIAL\n",
    "   - 94-95% de FKs sin referencias en la muestra (causado por muestreo independiente)\n",
    "   - En el dataset completo, esta tasa deber√≠a ser cercana a 0%\n",
    "   - Acci√≥n: NO eliminar hu√©rfanos en ETL, validar con dataset completo\n",
    "\n",
    "#### 4. üí° OPORTUNIDADES DE FEATURE ENGINEERING\n",
    "   - Extraer edad y g√©nero desde CLIENT.birth_number\n",
    "   - Calcular antig√ºedad de cuenta desde ACCOUNT.date\n",
    "   - Crear variable target 'is_risky' en LOAN (status B o D)\n",
    "   - Calcular fecha de finalizaci√≥n de pr√©stamo en LOAN\n",
    "   - Agregar transacciones por cuenta para an√°lisis de comportamiento\n",
    "\n",
    "#### 5. üìä PATRONES DE NEGOCIO IDENTIFICADOS\n",
    "   - ~95% de pr√©stamos tienen estado A o C (bajo riesgo)\n",
    "   - Existencia de balances negativos (sobregiros permitidos)\n",
    "   - Mayor√≠a de clientes tienen 1 sola cuenta\n",
    "   - Concentraci√≥n de cuentas en ciertas regiones geogr√°ficas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1194ead",
   "metadata": {},
   "source": [
    "### 8.2 Plan de Transformaci√≥n ETL Detallado\n",
    "\n",
    "### üîÑ FASE 1: RAW ‚Üí PROCESSED (Limpieza y Estandarizaci√≥n)\n",
    "\n",
    "| ID | Problema | Acci√≥n de Transformaci√≥n | Prioridad |\n",
    "|----|----------|-------------------------|-----------|\n",
    "| T1 | Separador y comillas en CSV | Configurar lectura con sep=';' y quitar comillas | üî¥ CR√çTICA |\n",
    "| T2 | Nombres de columnas sucios | Aplicar limpieza: min√∫sculas, sin comillas, snake_case | üî¥ CR√çTICA |\n",
    "| T3 | Fechas como enteros (YYMMDD) | Parsear a formato datetime YYYY-MM-DD | üî¥ CR√çTICA |\n",
    "| T4 | Columna 'a1' en DEMOGRAPHIC | Renombrar a 'district_id' | üü° ALTA |\n",
    "| T5 | Columnas 'a11', 'a12', etc. | Renombrar a nombres descriptivos (avg_salary, unemployment_rate) | üü° ALTA |\n",
    "| T6 | Nulos funcionales en TRANS/ORDER | Reemplazar por 'INTERNAL' o 'NA_CASH' | üü° ALTA |\n",
    "| T7 | Validar integridad referencial | Marcar registros hu√©rfanos con flag 'is_orphan' | üü¢ MEDIA |\n",
    "| T8 | Valores vac√≠os vs NULL | Estandarizar todos a NULL | üü¢ MEDIA |\n",
    "\n",
    "### üéØ FASE 2: PROCESSED ‚Üí CURATED (Feature Engineering y Modelado)\n",
    "\n",
    "| ID | Feature | Descripci√≥n | Tabla | Prioridad |\n",
    "|----|---------|-------------|-------|-----------|\n",
    "| F1 | age | Calcular edad desde birth_number | CLIENT | üî¥ CR√çTICA |\n",
    "| F2 | gender | Extraer g√©nero desde birth_number (+50 en d√≠a = mujer) | CLIENT | üî¥ CR√çTICA |\n",
    "| F3 | account_age_months | Antig√ºedad de cuenta desde fecha apertura | ACCOUNT | üü° ALTA |\n",
    "| F4 | loan_end_date | Fecha fin = fecha inicio + duraci√≥n | LOAN | üü° ALTA |\n",
    "| F5 | is_risky | Target binario: 1 si status=B o D, 0 si A o C | LOAN | üî¥ CR√çTICA |\n",
    "| F6 | is_trans_outlier | Flag para transacciones at√≠picas (IQR method) | TRANS | üü¢ MEDIA |\n",
    "| F7 | is_loan_outlier | Flag para pr√©stamos at√≠picos (>95 percentil) | LOAN | üü¢ MEDIA |\n",
    "| F8 | avg_balance | Balance promedio por cuenta | ACCOUNT | üü° ALTA |\n",
    "| F9 | total_transactions | N√∫mero de transacciones por cuenta | ACCOUNT | üü° ALTA |\n",
    "| F10 | negative_balance_flag | 1 si alguna vez tuvo balance negativo | ACCOUNT | üü¢ MEDIA |\n",
    "\n",
    "### üìä FASE 3: MODELADO DIMENSIONAL (Para An√°lisis)\n",
    "\n",
    "**Tablas de Hechos (Fact Tables):**\n",
    "- fact_transactions: Agregaci√≥n de TRANS por cuenta\n",
    "- fact_loans: Tabla de pr√©stamos enriquecida con features\n",
    "\n",
    "**Tablas de Dimensiones (Dimension Tables):**\n",
    "- dim_client: Clientes con edad, g√©nero, regi√≥n\n",
    "- dim_account: Cuentas con m√©tricas agregadas\n",
    "- dim_geographic: Datos demogr√°ficos por distrito\n",
    "- dim_date: Dimensi√≥n de tiempo para an√°lisis temporal\n",
    "\n",
    "\n",
    "### 8.3 Recomendaciones Finales\n",
    "\n",
    "### üéØ RECOMENDACIONES PARA EL PIPELINE ETL\n",
    "\n",
    "#### 1. üî¥ PRIORIDAD CR√çTICA - Implementar Inmediatamente\n",
    "   - ‚úì Configurar lectura correcta de CSVs (separador, encoding)\n",
    "   - ‚úì Parsear fechas de YYMMDD a datetime\n",
    "   - ‚úì Extraer edad y g√©nero desde birth_number\n",
    "   - ‚úì Crear variable target 'is_risky' para modelos de ML\n",
    "\n",
    "#### 2. üü° PRIORIDAD ALTA - Implementar en Sprint 1\n",
    "   - ‚úì Renombrar columnas cr√≠pticas (a1 ‚Üí district_id, a11 ‚Üí avg_salary)\n",
    "   - ‚úì Tratar nulos funcionales con etiquetas de negocio\n",
    "   - ‚úì Calcular features temporales (antig√ºedad, fecha_fin_prestamo)\n",
    "   - ‚úì Validar integridad referencial en dataset completo\n",
    "\n",
    "#### 3. üü¢ PRIORIDAD MEDIA - Implementar en Sprint 2\n",
    "   - ‚úì Marcar outliers para an√°lisis de fraude\n",
    "   - ‚úì Agregar m√©tricas por cuenta (balance promedio, total transacciones)\n",
    "   - ‚úì Crear flags de comportamiento (sobregiros, inactividad)\n",
    "   - ‚úì Implementar data quality checks automatizados\n",
    "\n",
    "#### 4. üìä AN√ÅLISIS ADICIONALES RECOMENDADOS\n",
    "   - ‚úì An√°lisis de serie temporal de transacciones\n",
    "   - ‚úì Segmentaci√≥n de clientes por comportamiento\n",
    "   - ‚úì Modelo de predicci√≥n de riesgo crediticio\n",
    "   - ‚úì An√°lisis de correlaci√≥n entre variables demogr√°ficas y riesgo\n",
    "\n",
    "#### 5. ‚ö†Ô∏è  ADVERTENCIAS IMPORTANTES\n",
    "   - Los problemas de FK en la muestra NO deben replicarse en datos completos\n",
    "   - NO eliminar registros hu√©rfanos sin validar con datos completos\n",
    "   - Los outliers pueden ser v√°lidos (VIP, fraude) - marcar, no eliminar\n",
    "   - Los balances negativos son v√°lidos - indican sobregiros permitidos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c287999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el archivo: ./data_original/trans_millon.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9836/2609291857.py:21: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path, sep=';', encoding='iso-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas totales originales: 1,056,320\n",
      "Tomando una muestra del 50.0% (528,160 filas)\n",
      "\n",
      "‚úÖ Archivo muestreado guardado exitosamente.\n",
      "El nuevo archivo './data_original/trans.csv' contiene 528,160 filas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# La ruta de tu archivo trans.csv original\n",
    "INPUT_FILE = './data_original/trans_millon.csv'\n",
    "# La ruta donde guardar√°s el archivo muestreado\n",
    "OUTPUT_FILE = './data_original/trans.csv' # Usaremos el mismo nombre para simplificar la corrida de Glue\n",
    "# Fracci√≥n de datos a mantener (10% de 1 mill√≥n es 100,000 filas)\n",
    "SAMPLE_FRACTION = 0.5\n",
    "\n",
    "def sample_transactions(input_path: str, output_path: str, frac: float):\n",
    "    \"\"\"Carga trans.csv, toma una muestra y la guarda, manteniendo la cabecera original.\"\"\"\n",
    "    \n",
    "    print(f\"Cargando el archivo: {input_path}\")\n",
    "    \n",
    "    # Cargar solo las columnas necesarias para acelerar (opcional)\n",
    "    # y asegurarse de que el separador sea el punto y coma\n",
    "    try:\n",
    "        # Nota: Usamos engine='python' si hay problemas con el separador o el tama√±o\n",
    "        df = pd.read_csv(input_path, sep=';', encoding='iso-8859-1')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontr√≥ el archivo en la ruta: {input_path}\")\n",
    "        return\n",
    "\n",
    "    total_rows = len(df)\n",
    "    sample_size = int(total_rows * frac)\n",
    "    \n",
    "    print(f\"Filas totales originales: {total_rows:,}\")\n",
    "    print(f\"Tomando una muestra del {frac*100}% ({sample_size:,} filas)\")\n",
    "\n",
    "    # Tomar la muestra aleatoria\n",
    "    df_sampled = df.sample(n=sample_size, random_state=42) # Usamos random_state para reproducibilidad\n",
    "    \n",
    "    # Guardar el archivo muestreado\n",
    "    # Importante: Mantener el separador original (;) y no incluir el √≠ndice de Pandas\n",
    "    df_sampled.to_csv(output_path, sep=';', index=False, header=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Archivo muestreado guardado exitosamente.\")\n",
    "    print(f\"El nuevo archivo '{output_path}' contiene {len(df_sampled):,} filas.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Aseg√∫rate de colocar el archivo 'trans.csv' original en el mismo directorio\n",
    "    # donde ejecutas este script, o ajusta la ruta en INPUT_FILE.\n",
    "    sample_transactions(INPUT_FILE, OUTPUT_FILE, SAMPLE_FRACTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
