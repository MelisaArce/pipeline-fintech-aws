AWSTemplateFormatVersion: '2010-09-09'
Description: |
  Pipeline ETL Berka - MANUAL (RAW -> PROCESSED -> CURATED -> RDS)
  Incluye: S3 Data Lake, Glue Jobs Manuales, Crawler, Lambda On/Off de RDS,
  Athena, IAM Roles, RDS Publico accesible por IP y Glue.

Parameters:
  YourName:
    Type: String
    Description: Nombre base para los recursos (solo minusculas, sin espacios)
    Default: berka
    AllowedPattern: ^[a-z0-9]+$
    ConstraintDescription: Solo minusculas y numeros

  RDSUsername:
    Type: String
    Description: Usuario maestro de RDS MySQL
    Default: admin

  RDSPassword:
    Type: String
    Description: Contraseña de RDS (minimo 8 caracteres)
    NoEcho: true
    MinLength: 8

  AuthorizedIP:
    Type: String
    Description: Tu IP publica para acceder a RDS (181.x.x.x/32)
    Default: 0.0.0.0/0 # Valor por defecto seguro, mejor usar tu IP real

  VpcId:
    Type: String
    Description: ID del VPC (dejar vacio para usar el VPC por defecto)
    Default: ''

Resources:

# ============================================================================
#  S3 DATALAKE (Mantenido tal cual)
# ============================================================================
  DataLakeBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "${YourName}-datalake-${AWS::AccountId}-${AWS::Region}"
      VersioningConfiguration:
        Status: Suspended
      LifecycleConfiguration:
        Rules:
          - Id: ProjectExpirationRule
            Status: Enabled
            ExpirationInDays: 30
          - Id: AthenaResultsCleanup
            Status: Enabled
            Prefix: athena-results/
            ExpirationInDays: 7
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      Tags:
        - Key: Project
          Value: Berka-ETL

# ============================================================================
#  IAM ROLES
# ============================================================================

  GlueJobRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${YourName}-glue-job-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: glue.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AmazonRDSFullAccess
        - arn:aws:iam::aws:policy/CloudWatchLogsFullAccess # Para logs de Glue

  LambdaRDSPowerRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${YourName}-lambda-rds-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/AmazonRDSFullAccess
      
  # Rol para el Custom Resource (Subnet Finder)
  SubnetFinderRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${YourName}-SubnetFinderRole"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: EC2DescribePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ec2:DescribeSubnets
                  - ec2:DescribeVpcs
                  - ec2:DescribeRouteTables
                Resource: "*"

# ============================================================================
#  VPC Y SUBNETS (Custom Resource para encontrar subredes públicas)
# ============================================================================
  SubnetFinderFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${YourName}-subnet-finder"
      Handler: index.handler
      Runtime: python3.12 # Versión más reciente
      Role: !GetAtt SubnetFinderRole.Arn
      Timeout: 30
      MemorySize: 128
      Code:
        ZipFile: |
          import json
          import boto3
          import urllib.request

          def send_response(event, context, response_status, response_data, physical_resource_id=None):
              response_url = event['ResponseURL']
              response_body = json.dumps({
                  'Status': response_status,
                  'Reason': 'See the details in CloudWatch Log Stream: ' + context.log_stream_name,
                  'PhysicalResourceId': physical_resource_id or context.log_stream_name,
                  'StackId': event['StackId'],
                  'RequestId': event['RequestId'],
                  'LogicalResourceId': event['LogicalResourceId'],
                  'Data': response_data
              }).encode('utf-8')
              req = urllib.request.Request(response_url, data=response_body, method='PUT')
              req.add_header('Content-Type', '')
              urllib.request.urlopen(req)

          def is_subnet_public(ec2, subnet_id):
              try:
                  # Obtener la route table asociada a la subnet
                  route_tables = ec2.describe_route_tables(
                      Filters=[{'Name': 'association.subnet-id', 'Values': [subnet_id]}]
                  )
                  
                  # Si no hay route table asociada directamente, buscar la main route table del VPC
                  if not route_tables['RouteTables']:
                      subnets = ec2.describe_subnets(SubnetIds=[subnet_id])
                      vpc_id = subnets['Subnets'][0]['VpcId']
                      
                      # Buscar la main route table del VPC
                      route_tables = ec2.describe_route_tables(
                          Filters=[
                              {'Name': 'vpc-id', 'Values': [vpc_id]},
                              {'Name': 'association.main', 'Values': ['true']}
                          ]
                      )
                  
                  # Verificar si alguna route table tiene una ruta a un Internet Gateway
                  for rt in route_tables['RouteTables']:
                      for route in rt.get('Routes', []):
                          if route.get('GatewayId', '').startswith('igw-'):
                              return True
                  
                  return False
              except Exception as e:
                  # Manejar errores de descripción (e.g. permisos)
                  print(f'Error verificando subnet {subnet_id}: {str(e)}')
                  return False

          def handler(event, context):
              ec2 = boto3.client('ec2')
              vpc_id_param = event['ResourceProperties'].get('VpcId', '')
              
              try:
                  if event['RequestType'] == 'Delete':
                      send_response(event, context, 'SUCCESS', {})
                      return
                  
                  # Lógica para encontrar VPC ID
                  if not vpc_id_param or vpc_id_param.strip() == '':
                      vpcs_response = ec2.describe_vpcs(
                          Filters=[{'Name': 'isDefault', 'Values': ['true']}]
                      )
                      if not vpcs_response['Vpcs']:
                          raise Exception('No se encontra un VPC por defecto. Por favor, proporciona un VpcId.')
                      vpc_id = vpcs_response['Vpcs'][0]['VpcId']
                  else:
                      vpc_id = vpc_id_param.strip()
                  
                  # Obtener todas las subnets del VPC
                  all_subnets = ec2.describe_subnets(
                      Filters=[{'Name': 'vpc-id', 'Values': [vpc_id]}]
                  )
                  
                  # Clasificar subnets públicas
                  public_subnets = []
                  for subnet in all_subnets['Subnets']:
                      if is_subnet_public(ec2, subnet['SubnetId']):
                          public_subnets.append(subnet)
                  
                  # Agrupar subnets públicas por AZ
                  public_subnets_by_az = {}
                  for subnet in public_subnets:
                      az = subnet['AvailabilityZone']
                      if az not in public_subnets_by_az:
                          public_subnets_by_az[az] = []
                      public_subnets_by_az[az].append(subnet['SubnetId'])
                  
                  if len(public_subnets_by_az) < 2:
                      # Esto es un requisito para el RDS, si no, falla la creación del SubnetGroup
                      raise Exception(f'Se requieren subnets publicas en al menos 2 zonas de disponibilidad. Encontradas: {len(public_subnets_by_az)}')
                  
                  # Seleccionar la primera subnet pública de al menos 2 AZs.
                  selected_public_subnets = [subnets[0] for subnets in public_subnets_by_az.values()][:2]
                  
                  result = {
                      'SubnetIds': ','.join(selected_public_subnets),
                      'VpcId': vpc_id
                  }
                  
                  send_response(event, context, 'SUCCESS', result)
              except Exception as e:
                  print(f'Error: {str(e)}')
                  send_response(event, context, 'FAILED', {'Error': str(e)})

  VPCSubnets:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt SubnetFinderFunction.Arn
      VpcId: !Ref VpcId

# ============================================================================
#  SECURITY GROUP Y RDS
# ============================================================================

  GlueSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for Glue jobs to access RDS
      VpcId: !GetAtt VPCSubnets.VpcId
      SecurityGroupEgress:
        - IpProtocol: -1 # Abrir a todo el tráfico de salida (necesario para S3, Logs y JDBC)
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub "${YourName}-glue-sg"

  RDSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Acceso a RDS desde IP, Glue y QuickSight
      VpcId: !GetAtt VPCSubnets.VpcId
      SecurityGroupIngress:
        # Regla 1: Acceso de tu IP (o 0.0.0.0/0 si se dejó por defecto)
        - IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          CidrIp: !Ref AuthorizedIP
          Description: Allow access from authorized IP

        # Regla 2: Acceso desde Glue Job (mediante su Security Group)
        - IpProtocol: tcp
          FromPort: 3306
          ToPort: 3306
          SourceSecurityGroupId: !Ref GlueSecurityGroup
          Description: Allow Glue jobs to connect
      Tags:
        - Key: Name
          Value: !Sub "${YourName}-rds-sg"
          
  RDSSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    DependsOn: VPCSubnets
    Properties:
      DBSubnetGroupName: !Sub "${YourName}-rds-subnet-group"
      DBSubnetGroupDescription: "Subnets públicas para RDS"
      SubnetIds:
        Fn::Split:
        - ","
        - Fn::GetAtt:
          - VPCSubnets
          - SubnetIds # Subnets públicas encontradas por el Custom Resource

  RDSInstance:
    Type: AWS::RDS::DBInstance
    # DeletionPolicy por defecto es 'Delete' (cumple requisito de no snapshot/costo)
    Properties:
      DBInstanceIdentifier: !Sub "${YourName}-mysql"
      AllocatedStorage: '20'
      DBInstanceClass: db.t3.micro
      Engine: mysql
      EngineVersion: '8.0.43'
      MasterUsername: !Ref RDSUsername
      MasterUserPassword: !Ref RDSPassword
      DBName: berka_warehouse
      DBSubnetGroupName: !Ref RDSSubnetGroup
      VPCSecurityGroups:
        - !Ref RDSSecurityGroup
      PubliclyAccessible: true # Requisito para QuickSight y tu IP
      BackupRetentionPeriod: 0 # Desactivar backups para reducir costos
      StorageType: gp2
      Tags:
        - Key: Project
          Value: Berka-ETL

# ============================================================================
#  GLUE CONNECTION, DATABASE, Y CRAWLER
# ============================================================================

  GlueRDSConnection:
    Type: AWS::Glue::Connection
    DependsOn:
      - RDSInstance
      - GlueSecurityGroup
    Properties:
      CatalogId: !Ref AWS::AccountId
      ConnectionInput:
        Name: !Sub "${YourName}-rds-connection"
        Description: JDBC connection to Berka MySQL RDS
        ConnectionType: JDBC
        PhysicalConnectionRequirements:
          SecurityGroupIdList:
            - !Ref GlueSecurityGroup
          # Usamos la primera subnet pública devuelta por el Custom Resource
          SubnetId: !Select [0, !Split [",", !GetAtt VPCSubnets.SubnetIds]] 
        ConnectionProperties:
          JDBC_CONNECTION_URL: !Sub "jdbc:mysql://${RDSInstance.Endpoint.Address}:${RDSInstance.Endpoint.Port}/berka_warehouse"
          USERNAME: !Ref RDSUsername
          PASSWORD: !Ref RDSPassword

  GlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Sub "${YourName}_berka_db" # Nombre más descriptivo
        Description: Glue Data Catalog para el dataset Berka Curado

  GlueCrawlerCurated:
    Type: AWS::Glue::Crawler
    Properties:
      Name: !Sub "${YourName}-curated-crawler"
      Role: !GetAtt GlueJobRole.Arn
      DatabaseName: !Ref GlueDatabase
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DataLakeBucket}/curated/berka/"
      Tags:
        Project: Berka-ETL

# ============================================================================
#  GLUE JOBS (MANUAL)
# ============================================================================
  
  # JOB 1: RAW -> PROCESSED
  GlueJobRawToProcessed:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${YourName}-raw-to-processed"
      Role: !GetAtt GlueJobRole.Arn
      Command:
        Name: glueetl
        ScriptLocation: !Sub "s3://${DataLakeBucket}/scripts/berka_raw_to_processed.py"
        PythonVersion: "3"
      GlueVersion: "4.0"
      WorkerType: G.1X
      NumberOfWorkers: 2
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--S3_BUCKET": !Ref DataLakeBucket
        "--RAW_PREFIX": "raw/berka/"
        "--PROCESSED_PREFIX": "processed/berka/"

  # JOB 2: PROCESSED -> CURATED
  GlueJobProcessedToCurated:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${YourName}-processed-to-curated"
      Role: !GetAtt GlueJobRole.Arn
      Command:
        Name: glueetl
        ScriptLocation: !Sub "s3://${DataLakeBucket}/scripts/berka_processed_to_curated.py"
        PythonVersion: "3"
      GlueVersion: "4.0"
      WorkerType: G.1X
      NumberOfWorkers: 2
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--S3_BUCKET": !Ref DataLakeBucket
        "--PROCESSED_PREFIX": "processed/berka/"
        "--CURATED_PREFIX": "curated/berka/"

  # JOB 3: CURATED -> RDS (Usando Conexión JDBC)
  GlueJobCuratedToRDS:
    Type: AWS::Glue::Job
    DependsOn: GlueRDSConnection # Depende de la conexión de red
    Properties:
      Name: !Sub "${YourName}-curated-to-rds"
      Role: !GetAtt GlueJobRole.Arn
      Connections:
        Connections:
          - !Sub "${YourName}-rds-connection"
      Command:
        Name: glueetl
        ScriptLocation: !Sub "s3://${DataLakeBucket}/scripts/berka_curated_to_rds.py"
        PythonVersion: "3"
      GlueVersion: "4.0"
      WorkerType: G.1X
      NumberOfWorkers: 2
      # Argumentos basados en la configuración de tu JSON
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--S3_BUCKET": !Ref DataLakeBucket
        "--CURATED_PREFIX": "curated/berka/"
        "--JDBC_URL": !Sub "jdbc:mysql://${RDSInstance.Endpoint.Address}:${RDSInstance.Endpoint.Port}/berka_warehouse"
        "--JDBC_USER": !Ref RDSUsername
        "--JDBC_PASSWORD": !Ref RDSPassword
        "--TARGET_TABLE": "berka_results" # De tu JSON
        "--EXECUTION_MODE": "GLUE"

# ============================================================================
#  LAMBDA RDS CONTROL (Para detener la instancia)
# ============================================================================
  RDSControlFunction:
    Type: AWS::Lambda::Function
    DependsOn: RDSInstance
    Properties:
      FunctionName: !Sub "${YourName}-rds-control"
      Handler: index.handler
      Runtime: python3.11
      Role: !GetAtt LambdaRDSPowerRole.Arn
      Timeout: 60
      Environment:
        Variables:
          RDS_INSTANCE_ID: !Ref RDSInstance
      Code:
        ZipFile: |
          import os
          import boto3
          rds = boto3.client('rds')
          RDS_INSTANCE_ID = os.environ['RDS_INSTANCE_ID']
          def handler(event, context):
              try:
                  response = rds.describe_db_instances(DBInstanceIdentifier=RDS_INSTANCE_ID)
                  status = response['DBInstances'][0]['DBInstanceStatus']
                  print(f"Current status: {status}")
                  if status == 'available':
                      print(f"Stopping RDS instance...")
                      rds.stop_db_instance(DBInstanceIdentifier=RDS_INSTANCE_ID)
                      return {'status': 'Stopping', 'instance': RDS_INSTANCE_ID}
                  elif status == 'stopped':
                      print(f"Starting RDS instance...")
                      rds.start_db_instance(DBInstanceIdentifier=RDS_INSTANCE_ID)
                      return {'status': 'Starting', 'instance': RDS_INSTANCE_ID}
                  else:
                      return {'status': 'NoAction', 'current_status': status}
              except Exception as e:
                  print(f"Error: {str(e)}")
                  return {'error': str(e)}

# ============================================================================
#  ATHENA WORKGROUP (Mantenido tal cual)
# ============================================================================
  AthenaWorkGroup:
    Type: AWS::Athena::WorkGroup
    Properties:
      Name: !Sub "${YourName}-workgroup"
      Description: Athena workgroup for Berka analytics
      WorkGroupConfiguration:
        ResultConfiguration:
          OutputLocation: !Sub "s3://${DataLakeBucket}/athena-results/"
        EnforceWorkGroupConfiguration: true
        PublishCloudWatchMetricsEnabled: true

# ============================================================================
# OUTPUTS
# ============================================================================
Outputs:
  S3BucketName:
    Description: Nombre del bucket S3 del Data Lake
    Value: !Ref DataLakeBucket

  RDSEndpoint:
    Description: Endpoint de la instancia RDS MySQL
    Value: !GetAtt RDSInstance.Endpoint.Address

  RDSConnectionString:
    Description: String de conexion JDBC para RDS
    Value: !Sub "jdbc:mysql://${RDSInstance.Endpoint.Address}:${RDSInstance.Endpoint.Port}/berka_warehouse?user=${RDSUsername}&password=${RDSPassword}"

  GlueDatabase:
    Description: Nombre de la base de datos Glue (Data Catalog)
    Value: !Ref GlueDatabase

  GlueConnection:
    Description: Nombre de la conexion Glue a RDS
    Value: !Sub "${YourName}-rds-connection"

  GlueJob1:
    Description: Job RAW -> PROCESSED
    Value: !Ref GlueJobRawToProcessed

  GlueJob2:
    Description: Job PROCESSED -> CURATED
    Value: !Ref GlueJobProcessedToCurated

  GlueJob3:
    Description: Job CURATED -> RDS
    Value: !Ref GlueJobCuratedToRDS

  GlueCrawler:
    Description: Crawler Curated
    Value: !Ref GlueCrawlerCurated

  QuickStartGuide:
    Description: Pasos para comenzar
    Value: !Sub |
      1. Subir scripts y datos (hacer antes del deploy): Ver script .sh.
      2. Ejecutar Job 1 (RAW->PROCESSED): aws glue start-job-run --job-name ${GlueJobRawToProcessed} --region ${AWS::Region}
      3. Ejecutar Job 2 (PROCESSED->CURATED): aws glue start-job-run --job-name ${GlueJobProcessedToCurated} --region ${AWS::Region}
      4. Ejecutar CRAWLER: aws glue start-crawler --name ${GlueCrawlerCurated} --region ${AWS::Region} (Espera que termine antes del paso 5)
      5. Ejecutar Job 3 (CURATED->RDS): aws glue start-job-run --job-name ${GlueJobCuratedToRDS} --region ${AWS::Region}
      6. Iniciar/Detener RDS: aws lambda invoke --function-name ${YourName}-rds-control --log-type Tail response.json